import argparse
import json
import os
from hashlib import md5
from io import BytesIO
from typing import Optional

import lmdb
from PIL import Image


def normalize_md5(img_bytes: bytes, size=(128, 32)) -> str:
    """Compute MD5 on normalized grayscale resized image bytes."""
    img = Image.open(BytesIO(img_bytes)).convert("L").resize(size, Image.BILINEAR)
    return md5(img.tobytes()).hexdigest()


def load_lmdb_paths(info_path: str):
    with open(info_path, "r", encoding="utf-8") as f:
        infos = json.load(f)
    val_paths, test_paths = [], []
    for item in infos:
        name = item.get("name", "").lower()
        path = item.get("path")
        if not path:
            continue
        if "val" in name:
            val_paths.append(path)
        elif "test" in name:
            test_paths.append(path)
    return val_paths, test_paths


def dump_md5_records(
    lmdb_path: str, source: str, hash_type: str, limit: Optional[int] = None
):
    env = lmdb.open(lmdb_path, readonly=True, lock=False, readahead=False)
    records = []
    with env.begin() as txn:
        num_bytes = txn.get(b"num-samples")
        total = int(num_bytes.decode("utf-8")) if num_bytes else 0
        upper = min(total, limit) if limit else total
        for idx in range(1, upper + 1):
            image_key = f"image-{idx:09d}".encode("utf-8")
            label_key = f"label-{idx:09d}".encode("utf-8")
            img_bytes = txn.get(image_key)
            label_bytes = txn.get(label_key)
            if img_bytes is None or label_bytes is None:
                continue
            label = label_bytes.decode("utf-8", errors="replace")
            md5_raw = md5(img_bytes).hexdigest()
            md5_norm = normalize_md5(img_bytes)
            rec = {
                "md5_raw": md5_raw,
                "md5_norm": md5_norm,
                "label": label,
                "source": source,
            }
            if hash_type == "raw":
                rec["md5"] = md5_raw
            elif hash_type == "norm":
                rec["md5"] = md5_norm
            records.append(rec)
    env.close()
    return records


def main():
    parser = argparse.ArgumentParser(
        description="Export MD5 fingerprints for Fudan scene val/test LMDBs."
    )
    parser.add_argument(
        "--info",
        default="/home/yzy/mmocr/data/fudan_benchmark/fudan_scene_lmdb_info.json",
        help="LMDB info json generated by inspect_fudan_lmdb.py.",
    )
    parser.add_argument(
        "--output",
        default="/home/yzy/mmocr/data/fudan_benchmark/fudan_scene_valtest_md5.json",
        help="Path to save md5 records list.",
    )
    parser.add_argument(
        "--output-set",
        default="/home/yzy/mmocr/data/fudan_benchmark/fudan_scene_valtest_md5_set.json",
        help="Path to save md5 set.",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="Optional limit for debugging.",
    )
    parser.add_argument(
        "--hash-type",
        choices=["raw", "norm", "both"],
        default="both",
        help="Which hash to emit as primary md5 field and sets.",
    )
    args = parser.parse_args()

    if not os.path.exists(args.info):
        raise FileNotFoundError(f"LMDB info json not found: {args.info}")

    val_paths, test_paths = load_lmdb_paths(args.info)
    if not val_paths and not test_paths:
        raise RuntimeError("No val/test LMDB paths found in info json.")

    os.makedirs(os.path.dirname(args.output), exist_ok=True)

    all_records = []
    for path in val_paths:
        all_records.extend(dump_md5_records(path, "scene_val", args.hash_type, args.limit))
    for path in test_paths:
        all_records.extend(dump_md5_records(path, "scene_test", args.hash_type, args.limit))

    with open(args.output, "w", encoding="utf-8") as f:
        json.dump(all_records, f, ensure_ascii=False, indent=2)
    md5_set = {"raw": [], "norm": []}
    for rec in all_records:
        md5_set["raw"].append(rec["md5_raw"])
        md5_set["norm"].append(rec["md5_norm"])
        if args.hash_type in ("raw", "norm"):
            # backward-compatible flat md5 for chosen type
            md5_set.setdefault("md5", []).append(rec[f"md5_{args.hash_type}"])
    with open(args.output_set, "w", encoding="utf-8") as f:
        json.dump(md5_set, f, ensure_ascii=False, indent=2)
    print(
        f"Exported {len(all_records)} fingerprints to {args.output} "
        f"and md5 set to {args.output_set} (hash_type={args.hash_type})"
    )


if __name__ == "__main__":
    main()
