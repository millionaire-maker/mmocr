2025/12/25 20:23:55 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 2068588885
    GPU 0: NVIDIA GeForce RTX 3090
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 11.1, V11.1.105
    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
    PyTorch: 1.10.2+cu111
    PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

    TorchVision: 0.11.3+cu111
    OpenCV: 4.12.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    dist_cfg: {'backend': 'nccl'}
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    seed: 2068588885
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/12/25 20:23:56 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=32, enable=True)
custom_hooks = [
    dict(
        min_delta=0.001,
        monitor='icdar/hmean',
        patience=12,
        rule='greater',
        type='EarlyStoppingHook'),
]
default_hooks = dict(
    checkpoint=dict(
        interval=3,
        max_keep_ckpts=3,
        rule='greater',
        save_best='icdar/hmean',
        type='CheckpointHook'),
    logger=dict(interval=5, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    sync_buffer=dict(type='SyncBuffersHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(
        draw_gt=False,
        draw_pred=False,
        enable=False,
        interval=1,
        show=False,
        type='VisualizationHook'))
default_scope = 'mmocr'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
launcher = 'none'
load_from = 'work_dirs/dbnetpp_r50_finetune_art_rctw_rects/epoch_102.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=10)
model = dict(
    backbone=dict(
        depth=50,
        frozen_stages=-1,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        norm_cfg=dict(requires_grad=True, type='BN'),
        norm_eval=True,
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        style='pytorch',
        type='mmdet.ResNet'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_size_divisor=32,
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='TextDetDataPreprocessor'),
    det_head=dict(
        in_channels=256,
        module_loss=dict(type='DBModuleLoss'),
        postprocessor=dict(
            epsilon_ratio=0.002, text_repr_type='quad',
            type='DBPostprocessor'),
        type='DBHead'),
    neck=dict(
        asf_cfg=dict(attention_type='ScaleChannelSpatial'),
        in_channels=[
            256,
            512,
            1024,
            2048,
        ],
        lateral_channels=256,
        type='FPNC'),
    type='DBNet')
optim_wrapper = dict(
    clip_grad=dict(max_norm=5, norm_type=2),
    loss_scale='dynamic',
    optimizer=dict(lr=0.0015, momentum=0.9, type='SGD', weight_decay=0.0001),
    type='AmpOptimWrapper')
param_schedluler = dict({'1': dict(end=108)})
param_scheduler = [
    dict(begin=0, by_epoch=True, end=2, start_factor=0.1, type='LinearLR'),
    dict(
        begin=2,
        by_epoch=True,
        end=200,
        eta_min=1e-07,
        power=0.9,
        type='PolyLR'),
]
randomness = dict(seed=None)
resume = True
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        datasets=[
            dict(
                ann_file='instances_val.json',
                data_root='data/art_mmocr',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
            dict(
                ann_file='instances_val.json',
                data_root='data/rctw17_mmocr',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
            dict(
                ann_file='instances_val.json',
                data_root='data/rects_mmocr',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
        ],
        pipeline=[
            dict(
                color_type='color_ignore_orientation',
                type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                4068,
                1024,
            ), type='Resize'),
            dict(
                type='LoadOCRAnnotations',
                with_bbox=True,
                with_label=True,
                with_polygon=True),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                    'instances',
                ),
                type='PackTextDetInputs'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(type='HmeanIOUMetric')
test_list = [
    dict(
        ann_file='instances_val.json',
        data_root='data/art_mmocr',
        pipeline=None,
        test_mode=True,
        type='OCRDataset'),
    dict(
        ann_file='instances_val.json',
        data_root='data/rctw17_mmocr',
        pipeline=None,
        test_mode=True,
        type='OCRDataset'),
    dict(
        ann_file='instances_val.json',
        data_root='data/rects_mmocr',
        pipeline=None,
        test_mode=True,
        type='OCRDataset'),
]
test_pipeline = [
    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        4068,
        1024,
    ), type='Resize'),
    dict(
        type='LoadOCRAnnotations',
        with_bbox=True,
        with_label=True,
        with_polygon=True),
    dict(
        meta_keys=(
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
            'instances',
        ),
        type='PackTextDetInputs'),
]
textdet_art_data_root = 'data/art_mmocr'
textdet_art_rctw_rects_data_root = 'data/textdet_finetune_art_rctw_rects'
textdet_art_rctw_rects_test = dict(
    ann_file='instances_val.json',
    data_root='data/textdet_finetune_art_rctw_rects',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
textdet_art_rctw_rects_train = dict(
    ann_file='instances_train.json',
    data_root='data/textdet_finetune_art_rctw_rects',
    filter_cfg=dict(filter_empty_gt=True, min_size=32),
    pipeline=None,
    type='OCRDataset')
textdet_art_test = dict(
    ann_file='instances_val.json',
    data_root='data/art_mmocr',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
textdet_art_train = dict(
    ann_file='instances_train.json',
    data_root='data/art_mmocr',
    filter_cfg=dict(filter_empty_gt=True, min_size=32),
    pipeline=None,
    type='OCRDataset')
textdet_rctw_data_root = 'data/rctw17_mmocr'
textdet_rctw_test = dict(
    ann_file='instances_val.json',
    data_root='data/rctw17_mmocr',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
textdet_rctw_train = dict(
    ann_file='instances_train.json',
    data_root='data/rctw17_mmocr',
    filter_cfg=dict(filter_empty_gt=True, min_size=32),
    pipeline=None,
    type='OCRDataset')
textdet_rects_data_root = 'data/rects_mmocr'
textdet_rects_test = dict(
    ann_file='instances_val.json',
    data_root='data/rects_mmocr',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
textdet_rects_train = dict(
    ann_file='instances_train.json',
    data_root='data/rects_mmocr',
    filter_cfg=dict(filter_empty_gt=True, min_size=32),
    pipeline=None,
    type='OCRDataset')
train_cfg = dict(max_epochs=108, type='EpochBasedTrainLoop', val_interval=3)
train_dataloader = dict(
    batch_size=32,
    dataset=dict(
        datasets=[
            dict(
                ann_file='instances_train.json',
                data_root='data/art_mmocr',
                filter_cfg=dict(filter_empty_gt=True, min_size=32),
                pipeline=None,
                type='OCRDataset'),
            dict(
                ann_file='instances_train.json',
                data_root='data/rctw17_mmocr',
                filter_cfg=dict(filter_empty_gt=True, min_size=32),
                pipeline=None,
                type='OCRDataset'),
            dict(
                ann_file='instances_train.json',
                data_root='data/rects_mmocr',
                filter_cfg=dict(filter_empty_gt=True, min_size=32),
                pipeline=None,
                type='OCRDataset'),
        ],
        pipeline=[
            dict(
                color_type='color_ignore_orientation',
                type='LoadImageFromFile'),
            dict(
                type='LoadOCRAnnotations',
                with_bbox=True,
                with_label=True,
                with_polygon=True),
            dict(
                brightness=0.12549019607843137,
                op='ColorJitter',
                saturation=0.5,
                type='TorchVisionWrapper'),
            dict(
                args=[
                    [
                        'Fliplr',
                        0.5,
                    ],
                    dict(cls='Affine', rotate=[
                        -10,
                        10,
                    ]),
                    [
                        'Resize',
                        [
                            0.5,
                            3.0,
                        ],
                    ],
                ],
                type='ImgAugWrapper'),
            dict(min_side_ratio=0.1, type='RandomCrop'),
            dict(keep_ratio=True, scale=(
                640,
                640,
            ), type='Resize'),
            dict(size=(
                640,
                640,
            ), type='Pad'),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                ),
                type='PackTextDetInputs'),
        ],
        type='ConcatDataset'),
    num_workers=8,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_list = [
    dict(
        ann_file='instances_train.json',
        data_root='data/art_mmocr',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        pipeline=None,
        type='OCRDataset'),
    dict(
        ann_file='instances_train.json',
        data_root='data/rctw17_mmocr',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        pipeline=None,
        type='OCRDataset'),
    dict(
        ann_file='instances_train.json',
        data_root='data/rects_mmocr',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        pipeline=None,
        type='OCRDataset'),
]
train_pipeline = [
    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),
    dict(
        type='LoadOCRAnnotations',
        with_bbox=True,
        with_label=True,
        with_polygon=True),
    dict(
        brightness=0.12549019607843137,
        op='ColorJitter',
        saturation=0.5,
        type='TorchVisionWrapper'),
    dict(
        args=[
            [
                'Fliplr',
                0.5,
            ],
            dict(cls='Affine', rotate=[
                -10,
                10,
            ]),
            [
                'Resize',
                [
                    0.5,
                    3.0,
                ],
            ],
        ],
        type='ImgAugWrapper'),
    dict(min_side_ratio=0.1, type='RandomCrop'),
    dict(keep_ratio=True, scale=(
        640,
        640,
    ), type='Resize'),
    dict(size=(
        640,
        640,
    ), type='Pad'),
    dict(
        meta_keys=(
            'img_path',
            'ori_shape',
            'img_shape',
        ),
        type='PackTextDetInputs'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        datasets=[
            dict(
                ann_file='instances_val.json',
                data_root='data/art_mmocr',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
            dict(
                ann_file='instances_val.json',
                data_root='data/rctw17_mmocr',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
            dict(
                ann_file='instances_val.json',
                data_root='data/rects_mmocr',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
        ],
        pipeline=[
            dict(
                color_type='color_ignore_orientation',
                type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                4068,
                1024,
            ), type='Resize'),
            dict(
                type='LoadOCRAnnotations',
                with_bbox=True,
                with_label=True,
                with_polygon=True),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                    'instances',
                ),
                type='PackTextDetInputs'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(type='HmeanIOUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='TextDetLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = 'work_dirs/dbnetpp_r50_finetune_art_rctw_rects/expA_end108'

2025/12/25 20:24:03 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/12/25 20:24:03 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
(LOWEST      ) EarlyStoppingHook                  
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
(LOWEST      ) EarlyStoppingHook                  
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/12/25 20:24:07 - mmengine - INFO - LR is set based on batch size of 32 and the current batch size is 32. Scaling the original LR by 1.0.
2025/12/25 20:24:08 - mmengine - INFO - load model from: torchvision://resnet50
2025/12/25 20:24:08 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
2025/12/25 20:24:08 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.0.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.1.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.2.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.3.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_conv.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_conv.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DBNet  

neck.asf_attn.channel_wise.0.conv.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_attn.channel_wise.1.conv.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_attn.spatial_wise.0.conv.weight - torch.Size([1, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_attn.spatial_wise.1.conv.weight - torch.Size([1, 1, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_attn.attention_wise.conv.weight - torch.Size([4, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

det_head.binarize.0.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.3.weight - torch.Size([64, 64, 2, 2]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.6.weight - torch.Size([64, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.6.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.0.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.3.weight - torch.Size([64, 64, 2, 2]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.6.weight - torch.Size([64, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.6.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of DBNet  
2025/12/25 20:24:08 - mmengine - INFO - Load checkpoint from work_dirs/dbnetpp_r50_finetune_art_rctw_rects/epoch_102.pth
2025/12/25 20:24:08 - mmengine - INFO - resumed epoch: 102, iter: 96594
2025/12/25 20:24:08 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/12/25 20:24:08 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/12/25 20:24:08 - mmengine - INFO - Checkpoints will be saved to /root/lanyun-tmp/mmocr/work_dirs/dbnetpp_r50_finetune_art_rctw_rects/expA_end108.
2025/12/25 20:24:40 - mmengine - INFO - Epoch(train) [103][  5/947]  lr: 7.9285e-04  eta: 10:03:04  time: 4.0895  data_time: 1.1100  memory: 18096  grad_norm: 9.7924  loss: 1.1873  loss_prob: 0.6946  loss_thr: 0.3752  loss_db: 0.1175
2025/12/25 20:24:52 - mmengine - INFO - Epoch(train) [103][ 10/947]  lr: 7.9285e-04  eta: 6:57:07  time: 4.4125  data_time: 1.1106  memory: 17793  grad_norm: 7.5988  loss: 1.1988  loss_prob: 0.6997  loss_thr: 0.3808  loss_db: 0.1183
2025/12/25 20:25:06 - mmengine - INFO - Epoch(train) [103][ 15/947]  lr: 7.9285e-04  eta: 6:00:18  time: 2.5354  data_time: 0.0039  memory: 17793  grad_norm: 6.8802  loss: 1.1719  loss_prob: 0.6868  loss_thr: 0.3687  loss_db: 0.1165
2025/12/25 20:25:17 - mmengine - INFO - Epoch(train) [103][ 20/947]  lr: 7.9285e-04  eta: 5:24:57  time: 2.4747  data_time: 0.0039  memory: 17793  grad_norm: 6.1203  loss: 1.1175  loss_prob: 0.6500  loss_thr: 0.3573  loss_db: 0.1102
2025/12/25 20:25:29 - mmengine - INFO - Epoch(train) [103][ 25/947]  lr: 7.9285e-04  eta: 5:05:40  time: 2.3829  data_time: 0.0029  memory: 17793  grad_norm: 6.3354  loss: 1.0911  loss_prob: 0.6307  loss_thr: 0.3535  loss_db: 0.1069
2025/12/25 20:25:43 - mmengine - INFO - Epoch(train) [103][ 30/947]  lr: 7.9285e-04  eta: 4:57:55  time: 2.6009  data_time: 0.0040  memory: 17793  grad_norm: 6.2487  loss: 1.1012  loss_prob: 0.6332  loss_thr: 0.3604  loss_db: 0.1076
2025/12/25 20:25:56 - mmengine - INFO - Epoch(train) [103][ 35/947]  lr: 7.9285e-04  eta: 4:50:23  time: 2.6941  data_time: 0.0044  memory: 17793  grad_norm: 6.2174  loss: 1.1635  loss_prob: 0.6706  loss_thr: 0.3792  loss_db: 0.1137
2025/12/25 20:26:08 - mmengine - INFO - Epoch(train) [103][ 40/947]  lr: 7.9285e-04  eta: 4:42:17  time: 2.5201  data_time: 0.0034  memory: 17793  grad_norm: 8.3724  loss: 1.1820  loss_prob: 0.6872  loss_thr: 0.3783  loss_db: 0.1165
2025/12/25 20:26:20 - mmengine - INFO - Epoch(train) [103][ 45/947]  lr: 7.9285e-04  eta: 4:34:23  time: 2.3439  data_time: 0.0030  memory: 17793  grad_norm: 11.1668  loss: 1.2032  loss_prob: 0.7090  loss_thr: 0.3748  loss_db: 0.1194
2025/12/25 20:26:33 - mmengine - INFO - Epoch(train) [103][ 50/947]  lr: 7.9285e-04  eta: 4:31:26  time: 2.4507  data_time: 0.0033  memory: 17793  grad_norm: 9.8804  loss: 1.1965  loss_prob: 0.7039  loss_thr: 0.3742  loss_db: 0.1184
2025/12/25 20:26:45 - mmengine - INFO - Epoch(train) [103][ 55/947]  lr: 7.9285e-04  eta: 4:27:17  time: 2.5321  data_time: 0.0033  memory: 17793  grad_norm: 7.3319  loss: 1.1459  loss_prob: 0.6618  loss_thr: 0.3720  loss_db: 0.1121
2025/12/25 20:26:58 - mmengine - INFO - Epoch(train) [103][ 60/947]  lr: 7.9285e-04  eta: 4:25:09  time: 2.5204  data_time: 0.0034  memory: 17793  grad_norm: 6.3571  loss: 1.1236  loss_prob: 0.6506  loss_thr: 0.3638  loss_db: 0.1093
2025/12/25 20:27:10 - mmengine - INFO - Epoch(train) [103][ 65/947]  lr: 7.9285e-04  eta: 4:21:59  time: 2.5157  data_time: 0.0032  memory: 17793  grad_norm: 8.4906  loss: 1.1339  loss_prob: 0.6610  loss_thr: 0.3601  loss_db: 0.1128
2025/12/25 20:27:24 - mmengine - INFO - Epoch(train) [103][ 70/947]  lr: 7.9285e-04  eta: 4:21:18  time: 2.5767  data_time: 0.0031  memory: 17793  grad_norm: 8.8658  loss: 1.1550  loss_prob: 0.6660  loss_thr: 0.3736  loss_db: 0.1155
2025/12/25 20:27:36 - mmengine - INFO - Epoch(train) [103][ 75/947]  lr: 7.9285e-04  eta: 4:19:11  time: 2.6112  data_time: 0.0033  memory: 17793  grad_norm: 7.2658  loss: 1.1520  loss_prob: 0.6759  loss_thr: 0.3641  loss_db: 0.1120
2025/12/25 20:27:49 - mmengine - INFO - Epoch(train) [103][ 80/947]  lr: 7.9285e-04  eta: 4:17:14  time: 2.4855  data_time: 0.0033  memory: 17793  grad_norm: 8.0389  loss: 1.1804  loss_prob: 0.7022  loss_thr: 0.3636  loss_db: 0.1146
2025/12/25 20:28:02 - mmengine - INFO - Epoch(train) [103][ 85/947]  lr: 7.9285e-04  eta: 4:16:03  time: 2.5299  data_time: 0.0031  memory: 17793  grad_norm: 7.1361  loss: 1.1094  loss_prob: 0.6434  loss_thr: 0.3568  loss_db: 0.1093
2025/12/25 20:28:14 - mmengine - INFO - Epoch(train) [103][ 90/947]  lr: 7.9285e-04  eta: 4:13:58  time: 2.4843  data_time: 0.0026  memory: 17793  grad_norm: 7.3260  loss: 1.0756  loss_prob: 0.6160  loss_thr: 0.3536  loss_db: 0.1060
2025/12/25 20:28:27 - mmengine - INFO - Epoch(train) [103][ 95/947]  lr: 7.9285e-04  eta: 4:13:31  time: 2.5331  data_time: 0.0033  memory: 17793  grad_norm: 8.1157  loss: 1.1155  loss_prob: 0.6508  loss_thr: 0.3534  loss_db: 0.1114
2025/12/25 20:28:39 - mmengine - INFO - Epoch(train) [103][100/947]  lr: 7.9285e-04  eta: 4:12:05  time: 2.5710  data_time: 0.0042  memory: 17793  grad_norm: 7.4060  loss: 1.1112  loss_prob: 0.6485  loss_thr: 0.3514  loss_db: 0.1114
2025/12/25 20:28:53 - mmengine - INFO - Epoch(train) [103][105/947]  lr: 7.9285e-04  eta: 4:12:01  time: 2.6054  data_time: 0.0043  memory: 17793  grad_norm: 9.0036  loss: 1.1577  loss_prob: 0.6773  loss_thr: 0.3676  loss_db: 0.1128
2025/12/25 20:29:05 - mmengine - INFO - Epoch(train) [103][110/947]  lr: 7.9285e-04  eta: 4:10:41  time: 2.5973  data_time: 0.0036  memory: 17793  grad_norm: 9.2241  loss: 1.1673  loss_prob: 0.6900  loss_thr: 0.3634  loss_db: 0.1140
2025/12/25 20:29:17 - mmengine - INFO - Epoch(train) [103][115/947]  lr: 7.9285e-04  eta: 4:09:14  time: 2.4227  data_time: 0.0031  memory: 17793  grad_norm: 7.2218  loss: 1.1242  loss_prob: 0.6597  loss_thr: 0.3528  loss_db: 0.1117
2025/12/25 20:29:29 - mmengine - INFO - Epoch(train) [103][120/947]  lr: 7.9285e-04  eta: 4:07:38  time: 2.3625  data_time: 0.0029  memory: 17793  grad_norm: 6.7116  loss: 1.1662  loss_prob: 0.6795  loss_thr: 0.3720  loss_db: 0.1147
2025/12/25 20:29:42 - mmengine - INFO - Epoch(train) [103][125/947]  lr: 7.9285e-04  eta: 4:06:50  time: 2.4220  data_time: 0.0028  memory: 17793  grad_norm: 7.0799  loss: 1.2110  loss_prob: 0.7013  loss_thr: 0.3916  loss_db: 0.1181
2025/12/25 20:29:55 - mmengine - INFO - Epoch(train) [103][130/947]  lr: 7.9285e-04  eta: 4:07:00  time: 2.6457  data_time: 0.0031  memory: 17793  grad_norm: 8.5750  loss: 1.2334  loss_prob: 0.7319  loss_thr: 0.3798  loss_db: 0.1217
2025/12/25 20:30:07 - mmengine - INFO - Epoch(train) [103][135/947]  lr: 7.9285e-04  eta: 4:05:22  time: 2.5162  data_time: 0.0029  memory: 17793  grad_norm: 7.7496  loss: 1.1906  loss_prob: 0.7090  loss_thr: 0.3642  loss_db: 0.1174
2025/12/25 20:30:19 - mmengine - INFO - Epoch(train) [103][140/947]  lr: 7.9285e-04  eta: 4:04:27  time: 2.3501  data_time: 0.0026  memory: 17793  grad_norm: 6.7578  loss: 1.1868  loss_prob: 0.6838  loss_thr: 0.3873  loss_db: 0.1157
2025/12/25 20:30:31 - mmengine - INFO - Epoch(train) [103][145/947]  lr: 7.9285e-04  eta: 4:03:14  time: 2.3866  data_time: 0.0028  memory: 17793  grad_norm: 8.1569  loss: 1.2026  loss_prob: 0.6904  loss_thr: 0.3943  loss_db: 0.1178
2025/12/25 20:30:44 - mmengine - INFO - Epoch(train) [103][150/947]  lr: 7.9285e-04  eta: 4:03:27  time: 2.5553  data_time: 0.0031  memory: 17793  grad_norm: 8.7566  loss: 1.1669  loss_prob: 0.6765  loss_thr: 0.3754  loss_db: 0.1150
2025/12/25 20:30:57 - mmengine - INFO - Epoch(train) [103][155/947]  lr: 7.9285e-04  eta: 4:02:53  time: 2.6511  data_time: 0.0037  memory: 17793  grad_norm: 9.1584  loss: 1.1920  loss_prob: 0.6928  loss_thr: 0.3832  loss_db: 0.1160
2025/12/25 20:31:09 - mmengine - INFO - Epoch(train) [103][160/947]  lr: 7.9285e-04  eta: 4:02:03  time: 2.4728  data_time: 0.0035  memory: 17793  grad_norm: 8.3503  loss: 1.1606  loss_prob: 0.6697  loss_thr: 0.3794  loss_db: 0.1115
2025/12/25 20:31:21 - mmengine - INFO - Epoch(train) [103][165/947]  lr: 7.9285e-04  eta: 4:01:18  time: 2.4320  data_time: 0.0031  memory: 17793  grad_norm: 7.1685  loss: 1.1305  loss_prob: 0.6513  loss_thr: 0.3688  loss_db: 0.1104
2025/12/25 20:31:34 - mmengine - INFO - Epoch(train) [103][170/947]  lr: 7.9285e-04  eta: 4:00:46  time: 2.4753  data_time: 0.0034  memory: 17793  grad_norm: 7.6817  loss: 1.1778  loss_prob: 0.6831  loss_thr: 0.3786  loss_db: 0.1162
2025/12/25 20:31:48 - mmengine - INFO - Epoch(train) [103][175/947]  lr: 7.9285e-04  eta: 4:00:53  time: 2.6276  data_time: 0.0036  memory: 17793  grad_norm: 6.7194  loss: 1.1520  loss_prob: 0.6662  loss_thr: 0.3728  loss_db: 0.1129
2025/12/25 20:32:01 - mmengine - INFO - Epoch(train) [103][180/947]  lr: 7.9285e-04  eta: 4:00:45  time: 2.7046  data_time: 0.0035  memory: 17793  grad_norm: 6.7934  loss: 1.1003  loss_prob: 0.6407  loss_thr: 0.3515  loss_db: 0.1081
2025/12/25 20:32:13 - mmengine - INFO - Epoch(train) [103][185/947]  lr: 7.9285e-04  eta: 3:59:48  time: 2.4948  data_time: 0.0038  memory: 17793  grad_norm: 7.2480  loss: 1.1014  loss_prob: 0.6404  loss_thr: 0.3527  loss_db: 0.1082
2025/12/25 20:32:25 - mmengine - INFO - Epoch(train) [103][190/947]  lr: 7.9285e-04  eta: 3:59:20  time: 2.4208  data_time: 0.0040  memory: 17793  grad_norm: 7.5303  loss: 1.1536  loss_prob: 0.6648  loss_thr: 0.3763  loss_db: 0.1124
2025/12/25 20:32:37 - mmengine - INFO - Epoch(train) [103][195/947]  lr: 7.9285e-04  eta: 3:58:36  time: 2.4558  data_time: 0.0036  memory: 17793  grad_norm: 8.2205  loss: 1.1867  loss_prob: 0.6827  loss_thr: 0.3878  loss_db: 0.1162
2025/12/25 20:32:49 - mmengine - INFO - Epoch(train) [103][200/947]  lr: 7.9285e-04  eta: 3:57:51  time: 2.3842  data_time: 0.0033  memory: 17793  grad_norm: 9.0315  loss: 1.2037  loss_prob: 0.7022  loss_thr: 0.3834  loss_db: 0.1181
2025/12/25 20:33:02 - mmengine - INFO - Epoch(train) [103][205/947]  lr: 7.9285e-04  eta: 3:57:38  time: 2.4892  data_time: 0.0034  memory: 17793  grad_norm: 8.8358  loss: 1.1530  loss_prob: 0.6730  loss_thr: 0.3683  loss_db: 0.1117
2025/12/25 20:33:15 - mmengine - INFO - Epoch(train) [103][210/947]  lr: 7.9285e-04  eta: 3:57:12  time: 2.5542  data_time: 0.0034  memory: 17793  grad_norm: 7.7702  loss: 1.1403  loss_prob: 0.6625  loss_thr: 0.3699  loss_db: 0.1079
2025/12/25 20:33:28 - mmengine - INFO - Epoch(train) [103][215/947]  lr: 7.9285e-04  eta: 3:57:04  time: 2.5720  data_time: 0.0033  memory: 17793  grad_norm: 9.1563  loss: 1.2233  loss_prob: 0.7333  loss_thr: 0.3716  loss_db: 0.1184
2025/12/25 20:33:40 - mmengine - INFO - Epoch(train) [103][220/947]  lr: 7.9285e-04  eta: 3:56:37  time: 2.5664  data_time: 0.0031  memory: 17793  grad_norm: 8.9962  loss: 1.1800  loss_prob: 0.7049  loss_thr: 0.3566  loss_db: 0.1185
2025/12/25 20:33:54 - mmengine - INFO - Epoch(train) [103][225/947]  lr: 7.9285e-04  eta: 3:56:42  time: 2.6173  data_time: 0.0032  memory: 17793  grad_norm: 7.8462  loss: 1.1550  loss_prob: 0.6711  loss_thr: 0.3692  loss_db: 0.1147
2025/12/25 20:34:07 - mmengine - INFO - Epoch(train) [103][230/947]  lr: 7.9285e-04  eta: 3:56:19  time: 2.6329  data_time: 0.0037  memory: 17793  grad_norm: 7.5314  loss: 1.1907  loss_prob: 0.6922  loss_thr: 0.3818  loss_db: 0.1168
2025/12/25 20:34:20 - mmengine - INFO - Epoch(train) [103][235/947]  lr: 7.9285e-04  eta: 3:56:10  time: 2.5770  data_time: 0.0040  memory: 17793  grad_norm: 7.1650  loss: 1.1602  loss_prob: 0.6775  loss_thr: 0.3676  loss_db: 0.1152
2025/12/25 20:34:31 - mmengine - INFO - Epoch(train) [103][240/947]  lr: 7.9285e-04  eta: 3:55:24  time: 2.4719  data_time: 0.0032  memory: 17793  grad_norm: 9.9105  loss: 1.1461  loss_prob: 0.6805  loss_thr: 0.3511  loss_db: 0.1145
2025/12/25 20:34:44 - mmengine - INFO - Epoch(train) [103][245/947]  lr: 7.9285e-04  eta: 3:54:57  time: 2.3908  data_time: 0.0030  memory: 17793  grad_norm: 9.7342  loss: 1.1415  loss_prob: 0.6776  loss_thr: 0.3514  loss_db: 0.1124
2025/12/25 20:34:56 - mmengine - INFO - Epoch(train) [103][250/947]  lr: 7.9285e-04  eta: 3:54:27  time: 2.4531  data_time: 0.0032  memory: 17793  grad_norm: 7.2609  loss: 1.1522  loss_prob: 0.6767  loss_thr: 0.3619  loss_db: 0.1136
2025/12/25 20:35:09 - mmengine - INFO - Epoch(train) [103][255/947]  lr: 7.9285e-04  eta: 3:54:07  time: 2.4790  data_time: 0.0030  memory: 17793  grad_norm: 10.1149  loss: 1.2268  loss_prob: 0.7285  loss_thr: 0.3767  loss_db: 0.1216
2025/12/25 20:35:23 - mmengine - INFO - Epoch(train) [103][260/947]  lr: 7.9285e-04  eta: 3:54:20  time: 2.6799  data_time: 0.0030  memory: 17793  grad_norm: 9.6215  loss: 1.2221  loss_prob: 0.7262  loss_thr: 0.3780  loss_db: 0.1179
2025/12/25 20:35:36 - mmengine - INFO - Epoch(train) [103][265/947]  lr: 7.9285e-04  eta: 3:54:13  time: 2.7466  data_time: 0.0036  memory: 17793  grad_norm: 6.8438  loss: 1.1844  loss_prob: 0.6975  loss_thr: 0.3728  loss_db: 0.1141
2025/12/25 20:35:48 - mmengine - INFO - Epoch(train) [103][270/947]  lr: 7.9285e-04  eta: 3:53:42  time: 2.5347  data_time: 0.0037  memory: 17793  grad_norm: 6.7726  loss: 1.2065  loss_prob: 0.7077  loss_thr: 0.3811  loss_db: 0.1177
2025/12/25 20:36:02 - mmengine - INFO - Epoch(train) [103][275/947]  lr: 7.9285e-04  eta: 3:53:42  time: 2.5656  data_time: 0.0037  memory: 17793  grad_norm: 7.7938  loss: 1.2129  loss_prob: 0.7052  loss_thr: 0.3883  loss_db: 0.1194
2025/12/25 20:36:15 - mmengine - INFO - Epoch(train) [103][280/947]  lr: 7.9285e-04  eta: 3:53:27  time: 2.6436  data_time: 0.0035  memory: 17793  grad_norm: 8.8565  loss: 1.1465  loss_prob: 0.6579  loss_thr: 0.3752  loss_db: 0.1133
2025/12/25 20:36:27 - mmengine - INFO - Epoch(train) [103][285/947]  lr: 7.9285e-04  eta: 3:53:10  time: 2.5644  data_time: 0.0038  memory: 17793  grad_norm: 7.4740  loss: 1.0847  loss_prob: 0.6220  loss_thr: 0.3564  loss_db: 0.1063
2025/12/25 20:36:39 - mmengine - INFO - Epoch(train) [103][290/947]  lr: 7.9285e-04  eta: 3:52:39  time: 2.4790  data_time: 0.0038  memory: 17793  grad_norm: 6.0264  loss: 1.0894  loss_prob: 0.6299  loss_thr: 0.3510  loss_db: 0.1085
2025/12/25 20:36:51 - mmengine - INFO - Epoch(train) [103][295/947]  lr: 7.9285e-04  eta: 3:52:06  time: 2.3839  data_time: 0.0033  memory: 17793  grad_norm: 8.2066  loss: 1.1413  loss_prob: 0.6739  loss_thr: 0.3574  loss_db: 0.1100
2025/12/25 20:37:05 - mmengine - INFO - Epoch(train) [103][300/947]  lr: 7.9285e-04  eta: 3:52:08  time: 2.5554  data_time: 0.0036  memory: 17793  grad_norm: 9.7686  loss: 1.1428  loss_prob: 0.6772  loss_thr: 0.3571  loss_db: 0.1086
2025/12/25 20:37:17 - mmengine - INFO - Epoch(train) [103][305/947]  lr: 7.9285e-04  eta: 3:51:42  time: 2.5926  data_time: 0.0035  memory: 17793  grad_norm: 8.2085  loss: 1.0883  loss_prob: 0.6322  loss_thr: 0.3497  loss_db: 0.1064
2025/12/25 20:37:31 - mmengine - INFO - Epoch(train) [103][310/947]  lr: 7.9285e-04  eta: 3:51:46  time: 2.6136  data_time: 0.0037  memory: 17793  grad_norm: 8.4413  loss: 1.1256  loss_prob: 0.6567  loss_thr: 0.3580  loss_db: 0.1109
2025/12/25 20:37:43 - mmengine - INFO - Epoch(train) [103][315/947]  lr: 7.9285e-04  eta: 3:51:24  time: 2.6311  data_time: 0.0037  memory: 17793  grad_norm: 10.4054  loss: 1.1854  loss_prob: 0.6952  loss_thr: 0.3736  loss_db: 0.1167
2025/12/25 20:37:56 - mmengine - INFO - Epoch(train) [103][320/947]  lr: 7.9285e-04  eta: 3:50:58  time: 2.4590  data_time: 0.0031  memory: 17793  grad_norm: 8.8528  loss: 1.1120  loss_prob: 0.6435  loss_thr: 0.3590  loss_db: 0.1095
2025/12/25 20:38:08 - mmengine - INFO - Epoch(train) [103][325/947]  lr: 7.9285e-04  eta: 3:50:39  time: 2.4739  data_time: 0.0031  memory: 17793  grad_norm: 7.2785  loss: 1.0935  loss_prob: 0.6320  loss_thr: 0.3535  loss_db: 0.1081
2025/12/25 20:38:21 - mmengine - INFO - Epoch(train) [103][330/947]  lr: 7.9285e-04  eta: 3:50:31  time: 2.5756  data_time: 0.0032  memory: 17793  grad_norm: 8.3904  loss: 1.1980  loss_prob: 0.7114  loss_thr: 0.3706  loss_db: 0.1160
2025/12/25 20:38:34 - mmengine - INFO - Epoch(train) [103][335/947]  lr: 7.9285e-04  eta: 3:50:06  time: 2.5401  data_time: 0.0038  memory: 17793  grad_norm: 8.4751  loss: 1.2179  loss_prob: 0.7228  loss_thr: 0.3784  loss_db: 0.1166
2025/12/25 20:38:47 - mmengine - INFO - Epoch(train) [103][340/947]  lr: 7.9285e-04  eta: 3:50:08  time: 2.6010  data_time: 0.0046  memory: 17793  grad_norm: 7.7949  loss: 1.1886  loss_prob: 0.6923  loss_thr: 0.3798  loss_db: 0.1165
2025/12/25 20:39:02 - mmengine - INFO - Epoch(train) [103][345/947]  lr: 7.9285e-04  eta: 3:50:15  time: 2.8065  data_time: 0.0049  memory: 17793  grad_norm: 6.9746  loss: 1.1767  loss_prob: 0.6816  loss_thr: 0.3785  loss_db: 0.1166
2025/12/25 20:39:13 - mmengine - INFO - Epoch(train) [103][350/947]  lr: 7.9285e-04  eta: 3:49:46  time: 2.6093  data_time: 0.0048  memory: 17793  grad_norm: 6.4614  loss: 1.1298  loss_prob: 0.6492  loss_thr: 0.3690  loss_db: 0.1116
2025/12/25 20:39:26 - mmengine - INFO - Epoch(train) [103][355/947]  lr: 7.9285e-04  eta: 3:49:21  time: 2.4026  data_time: 0.0038  memory: 17793  grad_norm: 6.4541  loss: 1.1059  loss_prob: 0.6381  loss_thr: 0.3591  loss_db: 0.1088
2025/12/25 20:39:38 - mmengine - INFO - Epoch(train) [103][360/947]  lr: 7.9285e-04  eta: 3:48:58  time: 2.4347  data_time: 0.0034  memory: 17793  grad_norm: 6.4207  loss: 1.1225  loss_prob: 0.6513  loss_thr: 0.3622  loss_db: 0.1090
2025/12/25 20:39:50 - mmengine - INFO - Epoch(train) [103][365/947]  lr: 7.9285e-04  eta: 3:48:29  time: 2.3979  data_time: 0.0034  memory: 17793  grad_norm: 6.0260  loss: 1.1158  loss_prob: 0.6456  loss_thr: 0.3599  loss_db: 0.1102
2025/12/25 20:40:01 - mmengine - INFO - Epoch(train) [103][370/947]  lr: 7.9285e-04  eta: 3:47:58  time: 2.3438  data_time: 0.0027  memory: 17793  grad_norm: 7.1488  loss: 1.1050  loss_prob: 0.6320  loss_thr: 0.3634  loss_db: 0.1097
2025/12/25 20:40:13 - mmengine - INFO - Epoch(train) [103][375/947]  lr: 7.9285e-04  eta: 3:47:35  time: 2.3811  data_time: 0.0027  memory: 17793  grad_norm: 8.0830  loss: 1.1220  loss_prob: 0.6465  loss_thr: 0.3655  loss_db: 0.1100
2025/12/25 20:40:25 - mmengine - INFO - Epoch(train) [103][380/947]  lr: 7.9285e-04  eta: 3:47:04  time: 2.3783  data_time: 0.0030  memory: 17793  grad_norm: 6.7011  loss: 1.1114  loss_prob: 0.6410  loss_thr: 0.3610  loss_db: 0.1094
2025/12/25 20:40:37 - mmengine - INFO - Epoch(train) [103][385/947]  lr: 7.9285e-04  eta: 3:46:37  time: 2.3374  data_time: 0.0027  memory: 17793  grad_norm: 6.4290  loss: 1.0904  loss_prob: 0.6244  loss_thr: 0.3594  loss_db: 0.1066
2025/12/25 20:40:49 - mmengine - INFO - Epoch(train) [103][390/947]  lr: 7.9285e-04  eta: 3:46:10  time: 2.3579  data_time: 0.0026  memory: 17793  grad_norm: 7.6920  loss: 1.1425  loss_prob: 0.6619  loss_thr: 0.3700  loss_db: 0.1106
