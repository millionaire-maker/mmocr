2025/12/19 17:59:24 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 977874013
    GPU 0: NVIDIA GeForce RTX 3090
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 11.1, V11.1.105
    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
    PyTorch: 1.10.2+cu111
    PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

    TorchVision: 0.11.3+cu111
    OpenCV: 4.12.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 977874013
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/12/19 17:59:24 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=32, enable=True)
custom_hooks = [
    dict(
        min_delta=0.001,
        monitor='icdar/hmean',
        patience=12,
        rule='greater',
        type='EarlyStoppingHook'),
]
default_hooks = dict(
    checkpoint=dict(
        interval=3,
        max_keep_ckpts=3,
        rule='greater',
        save_best='icdar/hmean',
        type='CheckpointHook'),
    logger=dict(interval=5, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    sync_buffer=dict(type='SyncBuffersHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(
        draw_gt=False,
        draw_pred=False,
        enable=False,
        interval=1,
        show=False,
        type='VisualizationHook'))
default_scope = 'mmocr'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
launcher = 'none'
load_from = 'work_dirs/dbnetpp_r50_pretrain_lsvt_ctw/best_icdar_hmean_epoch_60.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=10)
model = dict(
    backbone=dict(
        depth=50,
        frozen_stages=-1,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        norm_cfg=dict(requires_grad=True, type='BN'),
        norm_eval=True,
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        style='pytorch',
        type='mmdet.ResNet'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_size_divisor=32,
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='TextDetDataPreprocessor'),
    det_head=dict(
        in_channels=256,
        module_loss=dict(type='DBModuleLoss'),
        postprocessor=dict(
            epsilon_ratio=0.002, text_repr_type='quad',
            type='DBPostprocessor'),
        type='DBHead'),
    neck=dict(
        asf_cfg=dict(attention_type='ScaleChannelSpatial'),
        in_channels=[
            256,
            512,
            1024,
            2048,
        ],
        lateral_channels=256,
        type='FPNC'),
    type='DBNet')
optim_wrapper = dict(
    clip_grad=dict(max_norm=5, norm_type=2),
    loss_scale='dynamic',
    optimizer=dict(lr=0.0015, momentum=0.9, type='SGD', weight_decay=0.0001),
    type='AmpOptimWrapper')
param_scheduler = [
    dict(begin=0, by_epoch=True, end=2, start_factor=0.1, type='LinearLR'),
    dict(
        begin=2,
        by_epoch=True,
        end=200,
        eta_min=1e-07,
        power=0.9,
        type='PolyLR'),
]
randomness = dict(seed=None)
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        datasets=[
            dict(
                ann_file='instances_val.json',
                data_root='data/art_mmocr',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
            dict(
                ann_file='instances_val.json',
                data_root='data/rctw17_mmocr',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
            dict(
                ann_file='instances_val.json',
                data_root='data/rects_mmocr',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
        ],
        pipeline=[
            dict(
                color_type='color_ignore_orientation',
                type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                4068,
                1024,
            ), type='Resize'),
            dict(
                type='LoadOCRAnnotations',
                with_bbox=True,
                with_label=True,
                with_polygon=True),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                    'instances',
                ),
                type='PackTextDetInputs'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(type='HmeanIOUMetric')
test_list = [
    dict(
        ann_file='instances_val.json',
        data_root='data/art_mmocr',
        pipeline=None,
        test_mode=True,
        type='OCRDataset'),
    dict(
        ann_file='instances_val.json',
        data_root='data/rctw17_mmocr',
        pipeline=None,
        test_mode=True,
        type='OCRDataset'),
    dict(
        ann_file='instances_val.json',
        data_root='data/rects_mmocr',
        pipeline=None,
        test_mode=True,
        type='OCRDataset'),
]
test_pipeline = [
    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        4068,
        1024,
    ), type='Resize'),
    dict(
        type='LoadOCRAnnotations',
        with_bbox=True,
        with_label=True,
        with_polygon=True),
    dict(
        meta_keys=(
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
            'instances',
        ),
        type='PackTextDetInputs'),
]
textdet_art_data_root = 'data/art_mmocr'
textdet_art_rctw_rects_data_root = 'data/textdet_finetune_art_rctw_rects'
textdet_art_rctw_rects_test = dict(
    ann_file='instances_val.json',
    data_root='data/textdet_finetune_art_rctw_rects',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
textdet_art_rctw_rects_train = dict(
    ann_file='instances_train.json',
    data_root='data/textdet_finetune_art_rctw_rects',
    filter_cfg=dict(filter_empty_gt=True, min_size=32),
    pipeline=None,
    type='OCRDataset')
textdet_art_test = dict(
    ann_file='instances_val.json',
    data_root='data/art_mmocr',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
textdet_art_train = dict(
    ann_file='instances_train.json',
    data_root='data/art_mmocr',
    filter_cfg=dict(filter_empty_gt=True, min_size=32),
    pipeline=None,
    type='OCRDataset')
textdet_rctw_data_root = 'data/rctw17_mmocr'
textdet_rctw_test = dict(
    ann_file='instances_val.json',
    data_root='data/rctw17_mmocr',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
textdet_rctw_train = dict(
    ann_file='instances_train.json',
    data_root='data/rctw17_mmocr',
    filter_cfg=dict(filter_empty_gt=True, min_size=32),
    pipeline=None,
    type='OCRDataset')
textdet_rects_data_root = 'data/rects_mmocr'
textdet_rects_test = dict(
    ann_file='instances_val.json',
    data_root='data/rects_mmocr',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
textdet_rects_train = dict(
    ann_file='instances_train.json',
    data_root='data/rects_mmocr',
    filter_cfg=dict(filter_empty_gt=True, min_size=32),
    pipeline=None,
    type='OCRDataset')
train_cfg = dict(max_epochs=200, type='EpochBasedTrainLoop', val_interval=3)
train_dataloader = dict(
    batch_size=32,
    dataset=dict(
        datasets=[
            dict(
                ann_file='instances_train.json',
                data_root='data/art_mmocr',
                filter_cfg=dict(filter_empty_gt=True, min_size=32),
                pipeline=None,
                type='OCRDataset'),
            dict(
                ann_file='instances_train.json',
                data_root='data/rctw17_mmocr',
                filter_cfg=dict(filter_empty_gt=True, min_size=32),
                pipeline=None,
                type='OCRDataset'),
            dict(
                ann_file='instances_train.json',
                data_root='data/rects_mmocr',
                filter_cfg=dict(filter_empty_gt=True, min_size=32),
                pipeline=None,
                type='OCRDataset'),
        ],
        pipeline=[
            dict(
                color_type='color_ignore_orientation',
                type='LoadImageFromFile'),
            dict(
                type='LoadOCRAnnotations',
                with_bbox=True,
                with_label=True,
                with_polygon=True),
            dict(
                brightness=0.12549019607843137,
                op='ColorJitter',
                saturation=0.5,
                type='TorchVisionWrapper'),
            dict(
                args=[
                    [
                        'Fliplr',
                        0.5,
                    ],
                    dict(cls='Affine', rotate=[
                        -10,
                        10,
                    ]),
                    [
                        'Resize',
                        [
                            0.5,
                            3.0,
                        ],
                    ],
                ],
                type='ImgAugWrapper'),
            dict(min_side_ratio=0.1, type='RandomCrop'),
            dict(keep_ratio=True, scale=(
                640,
                640,
            ), type='Resize'),
            dict(size=(
                640,
                640,
            ), type='Pad'),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                ),
                type='PackTextDetInputs'),
        ],
        type='ConcatDataset'),
    num_workers=8,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_list = [
    dict(
        ann_file='instances_train.json',
        data_root='data/art_mmocr',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        pipeline=None,
        type='OCRDataset'),
    dict(
        ann_file='instances_train.json',
        data_root='data/rctw17_mmocr',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        pipeline=None,
        type='OCRDataset'),
    dict(
        ann_file='instances_train.json',
        data_root='data/rects_mmocr',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        pipeline=None,
        type='OCRDataset'),
]
train_pipeline = [
    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),
    dict(
        type='LoadOCRAnnotations',
        with_bbox=True,
        with_label=True,
        with_polygon=True),
    dict(
        brightness=0.12549019607843137,
        op='ColorJitter',
        saturation=0.5,
        type='TorchVisionWrapper'),
    dict(
        args=[
            [
                'Fliplr',
                0.5,
            ],
            dict(cls='Affine', rotate=[
                -10,
                10,
            ]),
            [
                'Resize',
                [
                    0.5,
                    3.0,
                ],
            ],
        ],
        type='ImgAugWrapper'),
    dict(min_side_ratio=0.1, type='RandomCrop'),
    dict(keep_ratio=True, scale=(
        640,
        640,
    ), type='Resize'),
    dict(size=(
        640,
        640,
    ), type='Pad'),
    dict(
        meta_keys=(
            'img_path',
            'ori_shape',
            'img_shape',
        ),
        type='PackTextDetInputs'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        datasets=[
            dict(
                ann_file='instances_val.json',
                data_root='data/art_mmocr',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
            dict(
                ann_file='instances_val.json',
                data_root='data/rctw17_mmocr',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
            dict(
                ann_file='instances_val.json',
                data_root='data/rects_mmocr',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
        ],
        pipeline=[
            dict(
                color_type='color_ignore_orientation',
                type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                4068,
                1024,
            ), type='Resize'),
            dict(
                type='LoadOCRAnnotations',
                with_bbox=True,
                with_label=True,
                with_polygon=True),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                    'instances',
                ),
                type='PackTextDetInputs'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(type='HmeanIOUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='TextDetLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = 'work_dirs/dbnetpp_r50_finetune_art_rctw_rects'

2025/12/19 17:59:32 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/12/19 17:59:32 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
(LOWEST      ) EarlyStoppingHook                  
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
(LOWEST      ) EarlyStoppingHook                  
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/12/19 17:59:36 - mmengine - INFO - LR is set based on batch size of 32 and the current batch size is 32. Scaling the original LR by 1.0.
2025/12/19 17:59:37 - mmengine - INFO - load model from: torchvision://resnet50
2025/12/19 17:59:37 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
2025/12/19 17:59:38 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.0.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.1.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.2.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.3.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_conv.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_conv.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DBNet  

neck.asf_attn.channel_wise.0.conv.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_attn.channel_wise.1.conv.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_attn.spatial_wise.0.conv.weight - torch.Size([1, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_attn.spatial_wise.1.conv.weight - torch.Size([1, 1, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_attn.attention_wise.conv.weight - torch.Size([4, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

det_head.binarize.0.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.3.weight - torch.Size([64, 64, 2, 2]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.6.weight - torch.Size([64, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.6.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.0.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.3.weight - torch.Size([64, 64, 2, 2]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.6.weight - torch.Size([64, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.6.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of DBNet  
2025/12/19 17:59:38 - mmengine - INFO - Load checkpoint from work_dirs/dbnetpp_r50_pretrain_lsvt_ctw/best_icdar_hmean_epoch_60.pth
2025/12/19 17:59:38 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/12/19 17:59:38 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/12/19 17:59:38 - mmengine - INFO - Checkpoints will be saved to /root/lanyun-tmp/mmocr/work_dirs/dbnetpp_r50_finetune_art_rctw_rects.
2025/12/19 18:00:07 - mmengine - INFO - Epoch(train)   [1][  5/947]  lr: 1.5000e-04  eta: 12 days, 21:35:30  time: 5.8847  data_time: 2.5081  memory: 17990  grad_norm: inf  loss: 2.1785  loss_prob: 1.4322  loss_thr: 0.5289  loss_db: 0.2174
2025/12/19 18:00:21 - mmengine - INFO - Epoch(train)   [1][ 10/947]  lr: 1.5000e-04  eta: 9 days, 9:10:33  time: 4.2802  data_time: 1.2552  memory: 17789  grad_norm: inf  loss: 2.0614  loss_prob: 1.3334  loss_thr: 0.5242  loss_db: 0.2038
2025/12/19 18:00:32 - mmengine - INFO - Epoch(train)   [1][ 15/947]  lr: 1.5000e-04  eta: 7 days, 20:41:15  time: 2.4378  data_time: 0.0021  memory: 17789  grad_norm: 14.6150  loss: 1.8847  loss_prob: 1.1832  loss_thr: 0.5159  loss_db: 0.1856
2025/12/19 18:00:44 - mmengine - INFO - Epoch(train)   [1][ 20/947]  lr: 1.5000e-04  eta: 7 days, 6:02:08  time: 2.3364  data_time: 0.0019  memory: 17789  grad_norm: inf  loss: 1.8508  loss_prob: 1.1577  loss_thr: 0.5062  loss_db: 0.1869
2025/12/19 18:00:56 - mmengine - INFO - Epoch(train)   [1][ 25/947]  lr: 1.5000e-04  eta: 6 days, 20:50:47  time: 2.4542  data_time: 0.0020  memory: 17789  grad_norm: inf  loss: 1.8689  loss_prob: 1.1769  loss_thr: 0.5040  loss_db: 0.1881
2025/12/19 18:01:08 - mmengine - INFO - Epoch(train)   [1][ 30/947]  lr: 1.5000e-04  eta: 6 days, 13:35:05  time: 2.3706  data_time: 0.0019  memory: 17789  grad_norm: 14.8669  loss: 1.8000  loss_prob: 1.1226  loss_thr: 0.4971  loss_db: 0.1802
2025/12/19 18:01:19 - mmengine - INFO - Epoch(train)   [1][ 35/947]  lr: 1.5000e-04  eta: 6 days, 8:18:05  time: 2.2996  data_time: 0.0017  memory: 17789  grad_norm: 11.5271  loss: 1.7398  loss_prob: 1.0797  loss_thr: 0.4838  loss_db: 0.1763
2025/12/19 18:01:31 - mmengine - INFO - Epoch(train)   [1][ 40/947]  lr: 1.5000e-04  eta: 6 days, 4:28:34  time: 2.3037  data_time: 0.0018  memory: 17789  grad_norm: 10.3594  loss: 1.7433  loss_prob: 1.0902  loss_thr: 0.4768  loss_db: 0.1763
2025/12/19 18:01:43 - mmengine - INFO - Epoch(train)   [1][ 45/947]  lr: 1.5000e-04  eta: 6 days, 1:43:27  time: 2.3334  data_time: 0.0020  memory: 17789  grad_norm: 9.2951  loss: 1.7733  loss_prob: 1.1159  loss_thr: 0.4773  loss_db: 0.1802
2025/12/19 18:01:54 - mmengine - INFO - Epoch(train)   [1][ 50/947]  lr: 1.5000e-04  eta: 5 days, 22:46:12  time: 2.2811  data_time: 0.0019  memory: 17789  grad_norm: 8.8974  loss: 1.7832  loss_prob: 1.1193  loss_thr: 0.4830  loss_db: 0.1809
2025/12/19 18:02:06 - mmengine - INFO - Epoch(train)   [1][ 55/947]  lr: 1.5000e-04  eta: 5 days, 21:24:46  time: 2.3205  data_time: 0.0017  memory: 17789  grad_norm: 11.3061  loss: 1.9340  loss_prob: 1.2335  loss_thr: 0.5099  loss_db: 0.1906
2025/12/19 18:02:18 - mmengine - INFO - Epoch(train)   [1][ 60/947]  lr: 1.5000e-04  eta: 5 days, 19:57:09  time: 2.3938  data_time: 0.0017  memory: 17789  grad_norm: 11.5561  loss: 1.9958  loss_prob: 1.2792  loss_thr: 0.5208  loss_db: 0.1958
2025/12/19 18:02:29 - mmengine - INFO - Epoch(train)   [1][ 65/947]  lr: 1.5000e-04  eta: 5 days, 18:17:27  time: 2.3038  data_time: 0.0017  memory: 17789  grad_norm: 8.8921  loss: 1.9219  loss_prob: 1.2106  loss_thr: 0.5190  loss_db: 0.1922
2025/12/19 18:02:40 - mmengine - INFO - Epoch(train)   [1][ 70/947]  lr: 1.5000e-04  eta: 5 days, 16:52:05  time: 2.2514  data_time: 0.0017  memory: 17789  grad_norm: 9.0962  loss: 1.7989  loss_prob: 1.1219  loss_thr: 0.4961  loss_db: 0.1809
2025/12/19 18:02:54 - mmengine - INFO - Epoch(train)   [1][ 75/947]  lr: 1.5000e-04  eta: 5 days, 17:51:50  time: 2.5696  data_time: 0.0019  memory: 17789  grad_norm: 12.5860  loss: 1.9413  loss_prob: 1.2432  loss_thr: 0.5083  loss_db: 0.1898
2025/12/19 18:03:07 - mmengine - INFO - Epoch(train)   [1][ 80/947]  lr: 1.5000e-04  eta: 5 days, 17:25:51  time: 2.6892  data_time: 0.0019  memory: 17789  grad_norm: 12.0808  loss: 1.9641  loss_prob: 1.2578  loss_thr: 0.5139  loss_db: 0.1923
2025/12/19 18:03:18 - mmengine - INFO - Epoch(train)   [1][ 85/947]  lr: 1.5000e-04  eta: 5 days, 16:28:04  time: 2.3970  data_time: 0.0018  memory: 17789  grad_norm: 8.6946  loss: 1.7411  loss_prob: 1.0787  loss_thr: 0.4883  loss_db: 0.1741
2025/12/19 18:03:29 - mmengine - INFO - Epoch(train)   [1][ 90/947]  lr: 1.5000e-04  eta: 5 days, 15:13:42  time: 2.2376  data_time: 0.0018  memory: 17789  grad_norm: 8.6204  loss: 1.6891  loss_prob: 1.0453  loss_thr: 0.4743  loss_db: 0.1694
2025/12/19 18:03:43 - mmengine - INFO - Epoch(train)   [1][ 95/947]  lr: 1.5000e-04  eta: 5 days, 15:26:40  time: 2.4115  data_time: 0.0018  memory: 17789  grad_norm: 8.2734  loss: 1.6843  loss_prob: 1.0408  loss_thr: 0.4728  loss_db: 0.1708
2025/12/19 18:03:55 - mmengine - INFO - Epoch(train)   [1][100/947]  lr: 1.5000e-04  eta: 5 days, 14:57:36  time: 2.5219  data_time: 0.0018  memory: 17789  grad_norm: 8.6018  loss: 1.7624  loss_prob: 1.0849  loss_thr: 0.4993  loss_db: 0.1782
2025/12/19 18:04:06 - mmengine - INFO - Epoch(train)   [1][105/947]  lr: 1.5000e-04  eta: 5 days, 14:20:55  time: 2.3583  data_time: 0.0017  memory: 17789  grad_norm: 11.4953  loss: 1.8534  loss_prob: 1.1686  loss_thr: 0.5014  loss_db: 0.1834
2025/12/19 18:04:18 - mmengine - INFO - Epoch(train)   [1][110/947]  lr: 1.5000e-04  eta: 5 days, 13:52:17  time: 2.3403  data_time: 0.0019  memory: 17789  grad_norm: 12.1268  loss: 1.8524  loss_prob: 1.1692  loss_thr: 0.4988  loss_db: 0.1844
2025/12/19 18:04:29 - mmengine - INFO - Epoch(train)   [1][115/947]  lr: 1.5000e-04  eta: 5 days, 13:18:42  time: 2.3298  data_time: 0.0019  memory: 17789  grad_norm: 9.1051  loss: 1.7473  loss_prob: 1.0758  loss_thr: 0.4927  loss_db: 0.1788
2025/12/19 18:04:40 - mmengine - INFO - Epoch(train)   [1][120/947]  lr: 1.5000e-04  eta: 5 days, 12:34:22  time: 2.2513  data_time: 0.0017  memory: 17789  grad_norm: 8.4328  loss: 1.6979  loss_prob: 1.0404  loss_thr: 0.4848  loss_db: 0.1728
2025/12/19 18:04:53 - mmengine - INFO - Epoch(train)   [1][125/947]  lr: 1.5000e-04  eta: 5 days, 12:36:27  time: 2.3697  data_time: 0.0018  memory: 17789  grad_norm: 9.4530  loss: 1.6463  loss_prob: 1.0058  loss_thr: 0.4722  loss_db: 0.1683
2025/12/19 18:05:05 - mmengine - INFO - Epoch(train)   [1][130/947]  lr: 1.5000e-04  eta: 5 days, 12:13:26  time: 2.4369  data_time: 0.0023  memory: 17789  grad_norm: 9.0620  loss: 1.6877  loss_prob: 1.0426  loss_thr: 0.4758  loss_db: 0.1692
2025/12/19 18:05:16 - mmengine - INFO - Epoch(train)   [1][135/947]  lr: 1.5000e-04  eta: 5 days, 11:41:28  time: 2.2887  data_time: 0.0022  memory: 17789  grad_norm: 8.1867  loss: 1.6366  loss_prob: 1.0133  loss_thr: 0.4621  loss_db: 0.1612
2025/12/19 18:05:28 - mmengine - INFO - Epoch(train)   [1][140/947]  lr: 1.5000e-04  eta: 5 days, 11:39:49  time: 2.3677  data_time: 0.0021  memory: 17789  grad_norm: 8.1169  loss: 1.6291  loss_prob: 1.0125  loss_thr: 0.4538  loss_db: 0.1628
2025/12/19 18:05:40 - mmengine - INFO - Epoch(train)   [1][145/947]  lr: 1.5000e-04  eta: 5 days, 11:22:55  time: 2.4216  data_time: 0.0020  memory: 17789  grad_norm: 9.0060  loss: 1.7480  loss_prob: 1.0908  loss_thr: 0.4809  loss_db: 0.1763
2025/12/19 18:05:52 - mmengine - INFO - Epoch(train)   [1][150/947]  lr: 1.5000e-04  eta: 5 days, 11:18:00  time: 2.4026  data_time: 0.0018  memory: 17789  grad_norm: 9.7505  loss: 1.8340  loss_prob: 1.1386  loss_thr: 0.5090  loss_db: 0.1863
2025/12/19 18:06:06 - mmengine - INFO - Epoch(train)   [1][155/947]  lr: 1.5000e-04  eta: 5 days, 11:29:40  time: 2.5343  data_time: 0.0020  memory: 17789  grad_norm: 8.8783  loss: 1.8108  loss_prob: 1.1209  loss_thr: 0.5033  loss_db: 0.1865
2025/12/19 18:06:17 - mmengine - INFO - Epoch(train)   [1][160/947]  lr: 1.5000e-04  eta: 5 days, 11:02:33  time: 2.4214  data_time: 0.0020  memory: 17789  grad_norm: 8.1705  loss: 1.6574  loss_prob: 1.0158  loss_thr: 0.4713  loss_db: 0.1703
2025/12/19 18:06:28 - mmengine - INFO - Epoch(train)   [1][165/947]  lr: 1.5000e-04  eta: 5 days, 10:40:20  time: 2.2455  data_time: 0.0018  memory: 17789  grad_norm: 7.9481  loss: 1.6304  loss_prob: 0.9962  loss_thr: 0.4699  loss_db: 0.1643
2025/12/19 18:06:40 - mmengine - INFO - Epoch(train)   [1][170/947]  lr: 1.5000e-04  eta: 5 days, 10:35:09  time: 2.3474  data_time: 0.0017  memory: 17789  grad_norm: 10.8791  loss: 1.7437  loss_prob: 1.0898  loss_thr: 0.4778  loss_db: 0.1761
2025/12/19 18:06:51 - mmengine - INFO - Epoch(train)   [1][175/947]  lr: 1.5000e-04  eta: 5 days, 10:12:59  time: 2.3364  data_time: 0.0017  memory: 17789  grad_norm: 11.2017  loss: 1.7924  loss_prob: 1.1242  loss_thr: 0.4840  loss_db: 0.1843
2025/12/19 18:07:03 - mmengine - INFO - Epoch(train)   [1][180/947]  lr: 1.5000e-04  eta: 5 days, 9:52:21  time: 2.2425  data_time: 0.0017  memory: 17789  grad_norm: 9.4212  loss: 1.8115  loss_prob: 1.1221  loss_thr: 0.5028  loss_db: 0.1866
2025/12/19 18:07:15 - mmengine - INFO - Epoch(train)   [1][185/947]  lr: 1.5000e-04  eta: 5 days, 9:56:11  time: 2.3813  data_time: 0.0019  memory: 17789  grad_norm: 10.5169  loss: 1.8956  loss_prob: 1.1900  loss_thr: 0.5142  loss_db: 0.1914
2025/12/19 18:07:27 - mmengine - INFO - Epoch(train)   [1][190/947]  lr: 1.5000e-04  eta: 5 days, 9:40:31  time: 2.4021  data_time: 0.0019  memory: 17789  grad_norm: 13.1327  loss: 1.8734  loss_prob: 1.1863  loss_thr: 0.4980  loss_db: 0.1891
2025/12/19 18:07:38 - mmengine - INFO - Epoch(train)   [1][195/947]  lr: 1.5000e-04  eta: 5 days, 9:23:59  time: 2.2755  data_time: 0.0019  memory: 17789  grad_norm: 11.4108  loss: 1.7688  loss_prob: 1.1162  loss_thr: 0.4739  loss_db: 0.1787
2025/12/19 18:07:51 - mmengine - INFO - Epoch(train)   [1][200/947]  lr: 1.5000e-04  eta: 5 days, 9:42:47  time: 2.4842  data_time: 0.0019  memory: 17789  grad_norm: 7.0943  loss: 1.8313  loss_prob: 1.1564  loss_thr: 0.4923  loss_db: 0.1826
2025/12/19 18:08:03 - mmengine - INFO - Epoch(train)   [1][205/947]  lr: 1.5000e-04  eta: 5 days, 9:37:21  time: 2.5517  data_time: 0.0019  memory: 17789  grad_norm: 8.7193  loss: 1.8467  loss_prob: 1.1552  loss_thr: 0.5055  loss_db: 0.1860
2025/12/19 18:08:15 - mmengine - INFO - Epoch(train)   [1][210/947]  lr: 1.5000e-04  eta: 5 days, 9:23:25  time: 2.3419  data_time: 0.0019  memory: 17789  grad_norm: 9.5129  loss: 1.7621  loss_prob: 1.0946  loss_thr: 0.4873  loss_db: 0.1802
2025/12/19 18:08:27 - mmengine - INFO - Epoch(train)   [1][215/947]  lr: 1.5000e-04  eta: 5 days, 9:13:10  time: 2.3043  data_time: 0.0019  memory: 17789  grad_norm: 7.7165  loss: 1.7073  loss_prob: 1.0576  loss_thr: 0.4767  loss_db: 0.1730
2025/12/19 18:08:38 - mmengine - INFO - Epoch(train)   [1][220/947]  lr: 1.5000e-04  eta: 5 days, 9:02:23  time: 2.3181  data_time: 0.0021  memory: 17789  grad_norm: 7.6716  loss: 1.6561  loss_prob: 1.0156  loss_thr: 0.4717  loss_db: 0.1687
2025/12/19 18:08:50 - mmengine - INFO - Epoch(train)   [1][225/947]  lr: 1.5000e-04  eta: 5 days, 8:50:18  time: 2.2987  data_time: 0.0020  memory: 17789  grad_norm: 7.4027  loss: 1.6405  loss_prob: 1.0046  loss_thr: 0.4687  loss_db: 0.1672
2025/12/19 18:09:01 - mmengine - INFO - Epoch(train)   [1][230/947]  lr: 1.5000e-04  eta: 5 days, 8:35:18  time: 2.2611  data_time: 0.0018  memory: 17789  grad_norm: 7.5923  loss: 1.6445  loss_prob: 1.0088  loss_thr: 0.4693  loss_db: 0.1665
2025/12/19 18:09:13 - mmengine - INFO - Epoch(train)   [1][235/947]  lr: 1.5000e-04  eta: 5 days, 8:33:19  time: 2.3282  data_time: 0.0020  memory: 17789  grad_norm: 8.5531  loss: 1.6335  loss_prob: 1.0031  loss_thr: 0.4644  loss_db: 0.1660
2025/12/19 18:09:25 - mmengine - INFO - Epoch(train)   [1][240/947]  lr: 1.5000e-04  eta: 5 days, 8:29:29  time: 2.4059  data_time: 0.0022  memory: 17789  grad_norm: 8.1756  loss: 1.6722  loss_prob: 1.0284  loss_thr: 0.4742  loss_db: 0.1696
2025/12/19 18:09:36 - mmengine - INFO - Epoch(train)   [1][245/947]  lr: 1.5000e-04  eta: 5 days, 8:23:07  time: 2.3704  data_time: 0.0019  memory: 17789  grad_norm: 8.4618  loss: 1.7370  loss_prob: 1.0882  loss_thr: 0.4736  loss_db: 0.1752
2025/12/19 18:09:47 - mmengine - INFO - Epoch(train)   [1][250/947]  lr: 1.5000e-04  eta: 5 days, 8:06:18  time: 2.2648  data_time: 0.0017  memory: 17789  grad_norm: 9.3132  loss: 1.7150  loss_prob: 1.0759  loss_thr: 0.4628  loss_db: 0.1764
2025/12/19 18:09:59 - mmengine - INFO - Epoch(train)   [1][255/947]  lr: 1.5000e-04  eta: 5 days, 8:01:13  time: 2.2697  data_time: 0.0018  memory: 17789  grad_norm: 9.5470  loss: 1.6699  loss_prob: 1.0263  loss_thr: 0.4684  loss_db: 0.1752
2025/12/19 18:10:11 - mmengine - INFO - Epoch(train)   [1][260/947]  lr: 1.5000e-04  eta: 5 days, 7:57:20  time: 2.3675  data_time: 0.0020  memory: 17789  grad_norm: 8.9430  loss: 1.7467  loss_prob: 1.0871  loss_thr: 0.4783  loss_db: 0.1814
2025/12/19 18:10:23 - mmengine - INFO - Epoch(train)   [1][265/947]  lr: 1.5000e-04  eta: 5 days, 7:50:25  time: 2.3492  data_time: 0.0019  memory: 17789  grad_norm: 8.5067  loss: 1.7570  loss_prob: 1.1013  loss_thr: 0.4736  loss_db: 0.1821
2025/12/19 18:10:35 - mmengine - INFO - Epoch(train)   [1][270/947]  lr: 1.5000e-04  eta: 5 days, 7:46:09  time: 2.3432  data_time: 0.0019  memory: 17789  grad_norm: 8.5383  loss: 1.6851  loss_prob: 1.0518  loss_thr: 0.4593  loss_db: 0.1739
2025/12/19 18:10:45 - mmengine - INFO - Epoch(train)   [1][275/947]  lr: 1.5000e-04  eta: 5 days, 7:27:24  time: 2.2360  data_time: 0.0019  memory: 17789  grad_norm: 8.2065  loss: 1.6812  loss_prob: 1.0434  loss_thr: 0.4660  loss_db: 0.1718
2025/12/19 18:10:57 - mmengine - INFO - Epoch(train)   [1][280/947]  lr: 1.5000e-04  eta: 5 days, 7:20:14  time: 2.2054  data_time: 0.0018  memory: 17789  grad_norm: 7.9422  loss: 1.7164  loss_prob: 1.0609  loss_thr: 0.4810  loss_db: 0.1745
2025/12/19 18:11:09 - mmengine - INFO - Epoch(train)   [1][285/947]  lr: 1.5000e-04  eta: 5 days, 7:20:10  time: 2.3644  data_time: 0.0019  memory: 17789  grad_norm: 8.2018  loss: 1.7507  loss_prob: 1.0897  loss_thr: 0.4820  loss_db: 0.1790
2025/12/19 18:11:20 - mmengine - INFO - Epoch(train)   [1][290/947]  lr: 1.5000e-04  eta: 5 days, 7:13:02  time: 2.3614  data_time: 0.0019  memory: 17789  grad_norm: 7.7407  loss: 1.6881  loss_prob: 1.0458  loss_thr: 0.4688  loss_db: 0.1735
2025/12/19 18:11:32 - mmengine - INFO - Epoch(train)   [1][295/947]  lr: 1.5000e-04  eta: 5 days, 7:06:21  time: 2.2985  data_time: 0.0018  memory: 17789  grad_norm: 7.0187  loss: 1.6622  loss_prob: 1.0261  loss_thr: 0.4655  loss_db: 0.1706
2025/12/19 18:11:44 - mmengine - INFO - Epoch(train)   [1][300/947]  lr: 1.5000e-04  eta: 5 days, 7:03:46  time: 2.3373  data_time: 0.0019  memory: 17789  grad_norm: 9.2080  loss: 1.7616  loss_prob: 1.0863  loss_thr: 0.4958  loss_db: 0.1796
2025/12/19 18:11:54 - mmengine - INFO - Epoch(train)   [1][305/947]  lr: 1.5000e-04  eta: 5 days, 6:50:50  time: 2.2734  data_time: 0.0018  memory: 17789  grad_norm: 10.1034  loss: 1.7510  loss_prob: 1.0804  loss_thr: 0.4932  loss_db: 0.1775
2025/12/19 18:12:06 - mmengine - INFO - Epoch(train)   [1][310/947]  lr: 1.5000e-04  eta: 5 days, 6:40:58  time: 2.1987  data_time: 0.0017  memory: 17789  grad_norm: 10.2345  loss: 1.7209  loss_prob: 1.0662  loss_thr: 0.4798  loss_db: 0.1749
2025/12/19 18:12:17 - mmengine - INFO - Epoch(train)   [1][315/947]  lr: 1.5000e-04  eta: 5 days, 6:36:11  time: 2.2726  data_time: 0.0018  memory: 17789  grad_norm: 11.3148  loss: 1.7638  loss_prob: 1.1021  loss_thr: 0.4843  loss_db: 0.1774
2025/12/19 18:12:29 - mmengine - INFO - Epoch(train)   [1][320/947]  lr: 1.5000e-04  eta: 5 days, 6:37:03  time: 2.3762  data_time: 0.0020  memory: 17789  grad_norm: 9.9929  loss: 1.6638  loss_prob: 1.0372  loss_thr: 0.4582  loss_db: 0.1684
2025/12/19 18:12:40 - mmengine - INFO - Epoch(train)   [1][325/947]  lr: 1.5000e-04  eta: 5 days, 6:25:56  time: 2.3088  data_time: 0.0020  memory: 17789  grad_norm: 10.1370  loss: 1.6353  loss_prob: 1.0094  loss_thr: 0.4571  loss_db: 0.1688
2025/12/19 18:12:52 - mmengine - INFO - Epoch(train)   [1][330/947]  lr: 1.5000e-04  eta: 5 days, 6:20:27  time: 2.2410  data_time: 0.0017  memory: 17789  grad_norm: 9.3032  loss: 1.6993  loss_prob: 1.0486  loss_thr: 0.4769  loss_db: 0.1737
2025/12/19 18:13:04 - mmengine - INFO - Epoch(train)   [1][335/947]  lr: 1.5000e-04  eta: 5 days, 6:24:29  time: 2.3962  data_time: 0.0019  memory: 17789  grad_norm: 7.7683  loss: 1.6943  loss_prob: 1.0441  loss_thr: 0.4777  loss_db: 0.1725
2025/12/19 18:13:15 - mmengine - INFO - Epoch(train)   [1][340/947]  lr: 1.5000e-04  eta: 5 days, 6:11:09  time: 2.3097  data_time: 0.0019  memory: 17789  grad_norm: 8.9212  loss: 1.6767  loss_prob: 1.0468  loss_thr: 0.4600  loss_db: 0.1699
2025/12/19 18:13:26 - mmengine - INFO - Epoch(train)   [1][345/947]  lr: 1.5000e-04  eta: 5 days, 6:01:07  time: 2.1554  data_time: 0.0017  memory: 17789  grad_norm: 8.3333  loss: 1.6622  loss_prob: 1.0349  loss_thr: 0.4593  loss_db: 0.1680
2025/12/19 18:13:38 - mmengine - INFO - Epoch(train)   [1][350/947]  lr: 1.5000e-04  eta: 5 days, 6:01:01  time: 2.2946  data_time: 0.0018  memory: 17789  grad_norm: 7.8507  loss: 1.6444  loss_prob: 1.0164  loss_thr: 0.4611  loss_db: 0.1669
2025/12/19 18:13:49 - mmengine - INFO - Epoch(train)   [1][355/947]  lr: 1.5000e-04  eta: 5 days, 5:57:03  time: 2.3583  data_time: 0.0018  memory: 17789  grad_norm: 8.5104  loss: 1.6925  loss_prob: 1.0539  loss_thr: 0.4663  loss_db: 0.1723
2025/12/19 18:14:01 - mmengine - INFO - Epoch(train)   [1][360/947]  lr: 1.5000e-04  eta: 5 days, 5:50:26  time: 2.2834  data_time: 0.0017  memory: 17789  grad_norm: 8.7835  loss: 1.7801  loss_prob: 1.1223  loss_thr: 0.4763  loss_db: 0.1814
2025/12/19 18:14:13 - mmengine - INFO - Epoch(train)   [1][365/947]  lr: 1.5000e-04  eta: 5 days, 5:52:59  time: 2.3560  data_time: 0.0018  memory: 17789  grad_norm: 11.6193  loss: 1.8714  loss_prob: 1.1985  loss_thr: 0.4847  loss_db: 0.1882
2025/12/19 18:14:24 - mmengine - INFO - Epoch(train)   [1][370/947]  lr: 1.5000e-04  eta: 5 days, 5:43:53  time: 2.3242  data_time: 0.0018  memory: 17789  grad_norm: 10.4808  loss: 1.7972  loss_prob: 1.1275  loss_thr: 0.4888  loss_db: 0.1809
2025/12/19 18:14:35 - mmengine - INFO - Epoch(train)   [1][375/947]  lr: 1.5000e-04  eta: 5 days, 5:37:51  time: 2.2220  data_time: 0.0018  memory: 17789  grad_norm: 7.4568  loss: 1.6870  loss_prob: 1.0333  loss_thr: 0.4835  loss_db: 0.1702
2025/12/19 18:14:48 - mmengine - INFO - Epoch(train)   [1][380/947]  lr: 1.5000e-04  eta: 5 days, 5:41:26  time: 2.3698  data_time: 0.0019  memory: 17789  grad_norm: 8.6435  loss: 1.6943  loss_prob: 1.0410  loss_thr: 0.4800  loss_db: 0.1733
2025/12/19 18:15:00 - mmengine - INFO - Epoch(train)   [1][385/947]  lr: 1.5000e-04  eta: 5 days, 5:43:01  time: 2.4607  data_time: 0.0019  memory: 17789  grad_norm: 8.7226  loss: 1.6909  loss_prob: 1.0426  loss_thr: 0.4735  loss_db: 0.1748
2025/12/19 18:15:11 - mmengine - INFO - Epoch(train)   [1][390/947]  lr: 1.5000e-04  eta: 5 days, 5:34:24  time: 2.3117  data_time: 0.0018  memory: 17789  grad_norm: 8.8077  loss: 1.7146  loss_prob: 1.0667  loss_thr: 0.4736  loss_db: 0.1743
2025/12/19 18:15:22 - mmengine - INFO - Epoch(train)   [1][395/947]  lr: 1.5000e-04  eta: 5 days, 5:30:48  time: 2.2462  data_time: 0.0018  memory: 17789  grad_norm: 8.2021  loss: 1.6558  loss_prob: 1.0239  loss_thr: 0.4626  loss_db: 0.1693
2025/12/19 18:15:34 - mmengine - INFO - Epoch(train)   [1][400/947]  lr: 1.5000e-04  eta: 5 days, 5:28:41  time: 2.3241  data_time: 0.0019  memory: 17789  grad_norm: 7.4240  loss: 1.6615  loss_prob: 1.0198  loss_thr: 0.4722  loss_db: 0.1696
2025/12/19 18:15:45 - mmengine - INFO - Epoch(train)   [1][405/947]  lr: 1.5000e-04  eta: 5 days, 5:24:23  time: 2.3132  data_time: 0.0019  memory: 17789  grad_norm: 7.5755  loss: 1.6377  loss_prob: 1.0038  loss_thr: 0.4674  loss_db: 0.1665
2025/12/19 18:15:57 - mmengine - INFO - Epoch(train)   [1][410/947]  lr: 1.5000e-04  eta: 5 days, 5:18:36  time: 2.2640  data_time: 0.0018  memory: 17789  grad_norm: 7.2944  loss: 1.6370  loss_prob: 1.0131  loss_thr: 0.4574  loss_db: 0.1665
2025/12/19 18:16:08 - mmengine - INFO - Epoch(train)   [1][415/947]  lr: 1.5000e-04  eta: 5 days, 5:15:56  time: 2.2828  data_time: 0.0019  memory: 17789  grad_norm: 9.3121  loss: 1.7285  loss_prob: 1.0749  loss_thr: 0.4763  loss_db: 0.1773
2025/12/19 18:16:19 - mmengine - INFO - Epoch(train)   [1][420/947]  lr: 1.5000e-04  eta: 5 days, 5:11:15  time: 2.2944  data_time: 0.0019  memory: 17789  grad_norm: 9.5587  loss: 1.6981  loss_prob: 1.0488  loss_thr: 0.4726  loss_db: 0.1766
2025/12/19 18:16:31 - mmengine - INFO - Epoch(train)   [1][425/947]  lr: 1.5000e-04  eta: 5 days, 5:06:43  time: 2.2671  data_time: 0.0018  memory: 17789  grad_norm: 7.2877  loss: 1.6905  loss_prob: 1.0488  loss_thr: 0.4667  loss_db: 0.1750
2025/12/19 18:16:44 - mmengine - INFO - Epoch(train)   [1][430/947]  lr: 1.5000e-04  eta: 5 days, 5:12:42  time: 2.4099  data_time: 0.0019  memory: 17789  grad_norm: 7.7716  loss: 1.6593  loss_prob: 1.0317  loss_thr: 0.4584  loss_db: 0.1692
2025/12/19 18:16:55 - mmengine - INFO - Epoch(train)   [1][435/947]  lr: 1.5000e-04  eta: 5 days, 5:10:33  time: 2.4419  data_time: 0.0020  memory: 17789  grad_norm: 8.1196  loss: 1.6169  loss_prob: 1.0002  loss_thr: 0.4515  loss_db: 0.1652
2025/12/19 18:17:07 - mmengine - INFO - Epoch(train)   [1][440/947]  lr: 1.5000e-04  eta: 5 days, 5:07:25  time: 2.3171  data_time: 0.0018  memory: 17789  grad_norm: 7.2687  loss: 1.6189  loss_prob: 0.9986  loss_thr: 0.4522  loss_db: 0.1681
2025/12/19 18:17:19 - mmengine - INFO - Epoch(train)   [1][445/947]  lr: 1.5000e-04  eta: 5 days, 5:07:53  time: 2.3527  data_time: 0.0019  memory: 17789  grad_norm: 8.9543  loss: 1.8037  loss_prob: 1.1331  loss_thr: 0.4848  loss_db: 0.1858
