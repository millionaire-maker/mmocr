2025/11/26 13:29:17 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1815573897
    GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU
    CUDA_HOME: /usr/local/cuda-11.8
    NVCC: Cuda compilation tools, release 11.8, V11.8.89
    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
    PyTorch: 2.1.2+cu121
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2+cu121
    OpenCV: 4.12.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1815573897
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/11/26 13:29:17 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=6)
default_hooks = dict(
    checkpoint=dict(interval=20, type='CheckpointHook'),
    logger=dict(interval=5, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    sync_buffer=dict(type='SyncBuffersHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(
        draw_gt=False,
        draw_pred=False,
        enable=False,
        interval=1,
        show=False,
        type='VisualizationHook'))
default_scope = 'mmocr'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=10)
model = dict(
    backbone=dict(
        depth=18,
        frozen_stages=-1,
        init_cfg=dict(checkpoint='torchvision://resnet18', type='Pretrained'),
        norm_cfg=dict(requires_grad=True, type='BN'),
        norm_eval=False,
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        style='pytorch',
        type='mmdet.ResNet'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_size_divisor=32,
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='TextDetDataPreprocessor'),
    det_head=dict(
        in_channels=256,
        module_loss=dict(type='DBModuleLoss'),
        postprocessor=dict(
            epsilon_ratio=0.002, text_repr_type='quad',
            type='DBPostprocessor'),
        type='DBHead'),
    neck=dict(
        asf_cfg=dict(attention_type='ScaleChannelSpatial'),
        in_channels=[
            64,
            128,
            256,
            512,
        ],
        lateral_channels=256,
        type='FPNC'),
    type='DBNet')
optim_wrapper = dict(
    loss_scale='dynamic',
    optimizer=dict(lr=0.007, momentum=0.9, type='SGD', weight_decay=0.0001),
    type='AmpOptimWrapper')
param_scheduler = [
    dict(end=1200, eta_min=1e-07, power=0.9, type='PolyLR'),
]
randomness = dict(seed=None)
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=6,
    dataset=dict(
        datasets=[
            dict(
                ann_file='instances_val.json',
                data_root='data/textdet_pretrain_lsvt_ctw',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
        ],
        pipeline=[
            dict(
                color_type='color_ignore_orientation',
                type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                4068,
                1024,
            ), type='Resize'),
            dict(
                type='LoadOCRAnnotations',
                with_bbox=True,
                with_label=True,
                with_polygon=True),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                    'instances',
                ),
                type='PackTextDetInputs'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(type='HmeanIOUMetric')
test_list = [
    dict(
        ann_file='instances_val.json',
        data_root='data/textdet_pretrain_lsvt_ctw',
        pipeline=None,
        test_mode=True,
        type='OCRDataset'),
]
test_pipeline = [
    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        4068,
        1024,
    ), type='Resize'),
    dict(
        type='LoadOCRAnnotations',
        with_bbox=True,
        with_label=True,
        with_polygon=True),
    dict(
        meta_keys=(
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
            'instances',
        ),
        type='PackTextDetInputs'),
]
textdet_lsvt_ctw_data_root = 'data/textdet_pretrain_lsvt_ctw'
textdet_lsvt_ctw_test = dict(
    ann_file='instances_val.json',
    data_root='data/textdet_pretrain_lsvt_ctw',
    pipeline=None,
    test_mode=True,
    type='OCRDataset')
textdet_lsvt_ctw_train = dict(
    ann_file='instances_train.json',
    data_root='data/textdet_pretrain_lsvt_ctw',
    filter_cfg=dict(filter_empty_gt=True, min_size=32),
    pipeline=None,
    type='OCRDataset')
train_cfg = dict(max_epochs=1200, type='EpochBasedTrainLoop', val_interval=20)
train_dataloader = dict(
    batch_size=8,
    dataset=dict(
        datasets=[
            dict(
                ann_file='instances_train.json',
                data_root='data/textdet_pretrain_lsvt_ctw',
                filter_cfg=dict(filter_empty_gt=True, min_size=32),
                pipeline=None,
                type='OCRDataset'),
        ],
        pipeline=[
            dict(
                color_type='color_ignore_orientation',
                type='LoadImageFromFile'),
            dict(
                type='LoadOCRAnnotations',
                with_bbox=True,
                with_label=True,
                with_polygon=True),
            dict(
                brightness=0.12549019607843137,
                op='ColorJitter',
                saturation=0.5,
                type='TorchVisionWrapper'),
            dict(
                args=[
                    [
                        'Fliplr',
                        0.5,
                    ],
                    dict(cls='Affine', rotate=[
                        -10,
                        10,
                    ]),
                    [
                        'Resize',
                        [
                            0.5,
                            3.0,
                        ],
                    ],
                ],
                type='ImgAugWrapper'),
            dict(min_side_ratio=0.1, type='RandomCrop'),
            dict(keep_ratio=True, scale=(
                640,
                640,
            ), type='Resize'),
            dict(size=(
                640,
                640,
            ), type='Pad'),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                ),
                type='PackTextDetInputs'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_list = [
    dict(
        ann_file='instances_train.json',
        data_root='data/textdet_pretrain_lsvt_ctw',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        pipeline=None,
        type='OCRDataset'),
]
train_pipeline = [
    dict(color_type='color_ignore_orientation', type='LoadImageFromFile'),
    dict(
        type='LoadOCRAnnotations',
        with_bbox=True,
        with_label=True,
        with_polygon=True),
    dict(
        brightness=0.12549019607843137,
        op='ColorJitter',
        saturation=0.5,
        type='TorchVisionWrapper'),
    dict(
        args=[
            [
                'Fliplr',
                0.5,
            ],
            dict(cls='Affine', rotate=[
                -10,
                10,
            ]),
            [
                'Resize',
                [
                    0.5,
                    3.0,
                ],
            ],
        ],
        type='ImgAugWrapper'),
    dict(min_side_ratio=0.1, type='RandomCrop'),
    dict(keep_ratio=True, scale=(
        640,
        640,
    ), type='Resize'),
    dict(size=(
        640,
        640,
    ), type='Pad'),
    dict(
        meta_keys=(
            'img_path',
            'ori_shape',
            'img_shape',
        ),
        type='PackTextDetInputs'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=6,
    dataset=dict(
        datasets=[
            dict(
                ann_file='instances_val.json',
                data_root='data/textdet_pretrain_lsvt_ctw',
                pipeline=None,
                test_mode=True,
                type='OCRDataset'),
        ],
        pipeline=[
            dict(
                color_type='color_ignore_orientation',
                type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                4068,
                1024,
            ), type='Resize'),
            dict(
                type='LoadOCRAnnotations',
                with_bbox=True,
                with_label=True,
                with_polygon=True),
            dict(
                meta_keys=(
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                    'instances',
                ),
                type='PackTextDetInputs'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(type='HmeanIOUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='TextDetLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = 'work_dirs/dbnetpp_r18_pretrain_lsvt_ctw'

2025/11/26 13:29:17 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/11/26 13:29:17 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/11/26 13:29:29 - mmengine - INFO - load model from: torchvision://resnet18
2025/11/26 13:29:29 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet18
2025/11/26 13:29:29 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from torchvision://resnet18 

backbone.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet18 

backbone.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer1.1.conv1.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.0.conv1.weight - torch.Size([128, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.0.downsample.0.weight - torch.Size([128, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.0.downsample.1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.0.downsample.1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.1.conv1.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet18 

backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet18 

neck.lateral_convs.0.conv.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.lateral_convs.1.conv.weight - torch.Size([256, 128, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.lateral_convs.2.conv.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.lateral_convs.3.conv.weight - torch.Size([256, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.0.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.1.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.2.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.smooth_convs.3.conv.weight - torch.Size([64, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_conv.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_conv.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of DBNet  

neck.asf_attn.channel_wise.0.conv.weight - torch.Size([64, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_attn.channel_wise.1.conv.weight - torch.Size([256, 64, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_attn.spatial_wise.0.conv.weight - torch.Size([1, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_attn.spatial_wise.1.conv.weight - torch.Size([1, 1, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

neck.asf_attn.attention_wise.conv.weight - torch.Size([4, 256, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

det_head.binarize.0.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.3.weight - torch.Size([64, 64, 2, 2]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.6.weight - torch.Size([64, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.binarize.6.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.0.weight - torch.Size([64, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.3.weight - torch.Size([64, 64, 2, 2]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.6.weight - torch.Size([64, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of DBNet  

det_head.threshold.6.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of DBNet  
2025/11/26 13:29:29 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/11/26 13:29:29 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/11/26 13:29:29 - mmengine - INFO - Checkpoints will be saved to /home/yzy/mmocr/work_dirs/dbnetpp_r18_pretrain_lsvt_ctw.
2025/11/26 13:29:34 - mmengine - INFO - Epoch(train)    [1][   5/6175]  lr: 7.0000e-03  eta: 81 days, 3:46:41  time: 0.9463  data_time: 0.2001  memory: 2377  loss: 15.8833  loss_prob: 12.4108  loss_thr: 2.4968  loss_db: 0.9756
2025/11/26 13:29:36 - mmengine - INFO - Epoch(train)    [1][  10/6175]  lr: 7.0000e-03  eta: 57 days, 2:21:40  time: 0.6658  data_time: 0.1100  memory: 2377  loss: 11.8496  loss_prob: 8.8571  loss_thr: 2.0174  loss_db: 0.9752
2025/11/26 13:29:38 - mmengine - INFO - Epoch(train)    [1][  15/6175]  lr: 7.0000e-03  eta: 50 days, 18:21:26  time: 0.4147  data_time: 0.0217  memory: 2377  loss: 6.5706  loss_prob: 4.2125  loss_thr: 1.3787  loss_db: 0.9794
2025/11/26 13:29:40 - mmengine - INFO - Epoch(train)    [1][  20/6175]  lr: 7.0000e-03  eta: 47 days, 12:28:17  time: 0.4424  data_time: 0.0200  memory: 2377  loss: 5.2105  loss_prob: 3.0230  loss_thr: 1.1961  loss_db: 0.9914
2025/11/26 13:29:42 - mmengine - INFO - Epoch(train)    [1][  25/6175]  lr: 7.0000e-03  eta: 44 days, 21:16:21  time: 0.4206  data_time: 0.0175  memory: 2377  loss: 5.0700  loss_prob: 2.9117  loss_thr: 1.1590  loss_db: 0.9993
2025/11/26 13:29:44 - mmengine - INFO - Epoch(train)    [1][  30/6175]  lr: 7.0000e-03  eta: 43 days, 21:56:56  time: 0.4280  data_time: 0.0187  memory: 2377  loss: 5.0499  loss_prob: 2.9031  loss_thr: 1.1468  loss_db: 1.0000
2025/11/26 13:29:47 - mmengine - INFO - Epoch(train)    [1][  35/6175]  lr: 7.0000e-03  eta: 43 days, 5:43:38  time: 0.4561  data_time: 0.0187  memory: 2377  loss: 5.0276  loss_prob: 2.8856  loss_thr: 1.1420  loss_db: 1.0000
2025/11/26 13:29:49 - mmengine - INFO - Epoch(train)    [1][  40/6175]  lr: 7.0000e-03  eta: 41 days, 23:30:16  time: 0.4218  data_time: 0.0184  memory: 2377  loss: 5.0024  loss_prob: 2.8587  loss_thr: 1.1436  loss_db: 1.0000
2025/11/26 13:29:51 - mmengine - INFO - Epoch(train)    [1][  45/6175]  lr: 7.0000e-03  eta: 41 days, 11:50:06  time: 0.4126  data_time: 0.0176  memory: 2377  loss: 4.9909  loss_prob: 2.8460  loss_thr: 1.1450  loss_db: 1.0000
2025/11/26 13:29:53 - mmengine - INFO - Epoch(train)    [1][  50/6175]  lr: 7.0000e-03  eta: 40 days, 19:38:07  time: 0.4218  data_time: 0.0187  memory: 2377  loss: 4.9765  loss_prob: 2.8346  loss_thr: 1.1419  loss_db: 1.0000
2025/11/26 13:29:55 - mmengine - INFO - Epoch(train)    [1][  55/6175]  lr: 7.0000e-03  eta: 40 days, 6:22:54  time: 0.4051  data_time: 0.0230  memory: 2377  loss: 4.9721  loss_prob: 2.8300  loss_thr: 1.1421  loss_db: 0.9999
2025/11/26 13:29:57 - mmengine - INFO - Epoch(train)    [1][  60/6175]  lr: 7.0000e-03  eta: 39 days, 21:27:59  time: 0.4113  data_time: 0.0224  memory: 2377  loss: 4.9626  loss_prob: 2.8254  loss_thr: 1.1373  loss_db: 0.9999
2025/11/26 13:29:59 - mmengine - INFO - Epoch(train)    [1][  65/6175]  lr: 7.0000e-03  eta: 39 days, 13:42:01  time: 0.4168  data_time: 0.0199  memory: 2377  loss: 4.9632  loss_prob: 2.8214  loss_thr: 1.1458  loss_db: 0.9960
2025/11/26 13:30:01 - mmengine - INFO - Epoch(train)    [1][  70/6175]  lr: 7.0000e-03  eta: 39 days, 9:26:24  time: 0.4243  data_time: 0.0200  memory: 2377  loss: 4.9508  loss_prob: 2.8194  loss_thr: 1.1355  loss_db: 0.9959
2025/11/26 13:30:03 - mmengine - INFO - Epoch(train)    [1][  75/6175]  lr: 7.0000e-03  eta: 39 days, 2:33:05  time: 0.4208  data_time: 0.0181  memory: 2377  loss: 4.9394  loss_prob: 2.8216  loss_thr: 1.1192  loss_db: 0.9987
2025/11/26 13:30:06 - mmengine - INFO - Epoch(train)    [1][  80/6175]  lr: 7.0000e-03  eta: 39 days, 5:24:09  time: 0.4436  data_time: 0.0185  memory: 2377  loss: 4.8964  loss_prob: 2.8207  loss_thr: 1.1157  loss_db: 0.9600
2025/11/26 13:30:08 - mmengine - INFO - Epoch(train)    [1][  85/6175]  lr: 7.0000e-03  eta: 38 days, 22:13:22  time: 0.4381  data_time: 0.0202  memory: 2377  loss: 4.8934  loss_prob: 2.8171  loss_thr: 1.1501  loss_db: 0.9263
2025/11/26 13:30:10 - mmengine - INFO - Epoch(train)    [1][  90/6175]  lr: 7.0000e-03  eta: 38 days, 15:54:01  time: 0.3983  data_time: 0.0208  memory: 2377  loss: 4.9434  loss_prob: 2.8184  loss_thr: 1.1600  loss_db: 0.9650
2025/11/26 13:30:12 - mmengine - INFO - Epoch(train)    [1][  95/6175]  lr: 7.0000e-03  eta: 38 days, 17:52:39  time: 0.4338  data_time: 0.0205  memory: 2377  loss: 4.9587  loss_prob: 2.8364  loss_thr: 1.1263  loss_db: 0.9960
2025/11/26 13:30:14 - mmengine - INFO - Epoch(train)    [1][ 100/6175]  lr: 7.0000e-03  eta: 38 days, 12:33:21  time: 0.4346  data_time: 0.0192  memory: 2377  loss: 4.9130  loss_prob: 2.8379  loss_thr: 1.1311  loss_db: 0.9439
2025/11/26 13:30:16 - mmengine - INFO - Epoch(train)    [1][ 105/6175]  lr: 7.0000e-03  eta: 38 days, 8:03:16  time: 0.4017  data_time: 0.0202  memory: 2377  loss: 4.8225  loss_prob: 2.8201  loss_thr: 1.1376  loss_db: 0.8648
2025/11/26 13:30:18 - mmengine - INFO - Epoch(train)    [1][ 110/6175]  lr: 7.0000e-03  eta: 38 days, 6:06:25  time: 0.4147  data_time: 0.0220  memory: 2377  loss: 4.7978  loss_prob: 2.8252  loss_thr: 1.1463  loss_db: 0.8264
2025/11/26 13:30:20 - mmengine - INFO - Epoch(train)    [1][ 115/6175]  lr: 7.0000e-03  eta: 38 days, 1:06:27  time: 0.4082  data_time: 0.0219  memory: 2377  loss: 4.7777  loss_prob: 2.8289  loss_thr: 1.1516  loss_db: 0.7972
2025/11/26 13:30:22 - mmengine - INFO - Epoch(train)    [1][ 120/6175]  lr: 7.0000e-03  eta: 37 days, 22:37:10  time: 0.4024  data_time: 0.0229  memory: 2377  loss: 4.7415  loss_prob: 2.8341  loss_thr: 1.1393  loss_db: 0.7680
2025/11/26 13:30:24 - mmengine - INFO - Epoch(train)    [1][ 125/6175]  lr: 7.0000e-03  eta: 37 days, 19:43:45  time: 0.4110  data_time: 0.0221  memory: 2377  loss: 4.6408  loss_prob: 2.8370  loss_thr: 1.1014  loss_db: 0.7024
2025/11/26 13:30:26 - mmengine - INFO - Epoch(train)    [1][ 130/6175]  lr: 7.0000e-03  eta: 37 days, 16:02:36  time: 0.4009  data_time: 0.0198  memory: 2377  loss: 4.5570  loss_prob: 2.8352  loss_thr: 1.0733  loss_db: 0.6486
2025/11/26 13:30:28 - mmengine - INFO - Epoch(train)    [1][ 135/6175]  lr: 7.0000e-03  eta: 37 days, 13:45:46  time: 0.4019  data_time: 0.0208  memory: 2377  loss: 4.6051  loss_prob: 2.8443  loss_thr: 1.1007  loss_db: 0.6600
2025/11/26 13:30:30 - mmengine - INFO - Epoch(train)    [1][ 140/6175]  lr: 7.0000e-03  eta: 37 days, 12:17:52  time: 0.4138  data_time: 0.0213  memory: 2377  loss: 4.6685  loss_prob: 2.8484  loss_thr: 1.0896  loss_db: 0.7305
2025/11/26 13:30:33 - mmengine - INFO - Epoch(train)    [1][ 145/6175]  lr: 7.0000e-03  eta: 37 days, 11:43:51  time: 0.4238  data_time: 0.0224  memory: 2377  loss: 4.7209  loss_prob: 2.8446  loss_thr: 1.0769  loss_db: 0.7994
2025/11/26 13:30:35 - mmengine - INFO - Epoch(train)    [1][ 150/6175]  lr: 7.0000e-03  eta: 37 days, 15:12:52  time: 0.4587  data_time: 0.0233  memory: 2377  loss: 4.7090  loss_prob: 2.8479  loss_thr: 1.0964  loss_db: 0.7647
2025/11/26 13:30:37 - mmengine - INFO - Epoch(train)    [1][ 155/6175]  lr: 7.0000e-03  eta: 37 days, 9:32:31  time: 0.4206  data_time: 0.0244  memory: 2377  loss: 4.7323  loss_prob: 2.8478  loss_thr: 1.0744  loss_db: 0.8101
2025/11/26 13:30:39 - mmengine - INFO - Epoch(train)    [1][ 160/6175]  lr: 7.0000e-03  eta: 37 days, 6:47:32  time: 0.3734  data_time: 0.0221  memory: 2377  loss: 4.6787  loss_prob: 2.8389  loss_thr: 1.0817  loss_db: 0.7581
2025/11/26 13:30:41 - mmengine - INFO - Epoch(train)    [1][ 165/6175]  lr: 7.0000e-03  eta: 37 days, 3:40:39  time: 0.3891  data_time: 0.0206  memory: 2377  loss: 4.5320  loss_prob: 2.8369  loss_thr: 1.0681  loss_db: 0.6271
2025/11/26 13:30:43 - mmengine - INFO - Epoch(train)    [1][ 170/6175]  lr: 7.0000e-03  eta: 37 days, 2:52:19  time: 0.4024  data_time: 0.0241  memory: 2377  loss: 4.5008  loss_prob: 2.8402  loss_thr: 1.0233  loss_db: 0.6373
2025/11/26 13:30:45 - mmengine - INFO - Epoch(train)    [1][ 175/6175]  lr: 7.0000e-03  eta: 37 days, 1:30:13  time: 0.4147  data_time: 0.0262  memory: 2377  loss: 4.5247  loss_prob: 2.8437  loss_thr: 1.0430  loss_db: 0.6380
2025/11/26 13:30:47 - mmengine - INFO - Epoch(train)    [1][ 180/6175]  lr: 7.0000e-03  eta: 36 days, 23:27:16  time: 0.4029  data_time: 0.0244  memory: 2377  loss: 4.5434  loss_prob: 2.8453  loss_thr: 1.0612  loss_db: 0.6368
2025/11/26 13:30:49 - mmengine - INFO - Epoch(train)    [1][ 185/6175]  lr: 7.0000e-03  eta: 36 days, 19:22:44  time: 0.3771  data_time: 0.0167  memory: 2377  loss: 4.4733  loss_prob: 2.8436  loss_thr: 1.0175  loss_db: 0.6121
2025/11/26 13:30:51 - mmengine - INFO - Epoch(train)    [1][ 190/6175]  lr: 7.0000e-03  eta: 36 days, 19:51:09  time: 0.3979  data_time: 0.0179  memory: 2377  loss: 4.3634  loss_prob: 2.8424  loss_thr: 0.9694  loss_db: 0.5516
2025/11/26 13:30:53 - mmengine - INFO - Epoch(train)    [1][ 195/6175]  lr: 7.0000e-03  eta: 36 days, 18:15:14  time: 0.4185  data_time: 0.0210  memory: 2377  loss: 4.4508  loss_prob: 2.8489  loss_thr: 1.0037  loss_db: 0.5981
2025/11/26 13:30:55 - mmengine - INFO - Epoch(train)    [1][ 200/6175]  lr: 7.0000e-03  eta: 36 days, 15:46:07  time: 0.3897  data_time: 0.0192  memory: 2377  loss: 4.5250  loss_prob: 2.8490  loss_thr: 1.0109  loss_db: 0.6652
2025/11/26 13:30:56 - mmengine - INFO - Epoch(train)    [1][ 205/6175]  lr: 7.0000e-03  eta: 36 days, 12:37:08  time: 0.3725  data_time: 0.0196  memory: 2377  loss: 4.4434  loss_prob: 2.8418  loss_thr: 0.9932  loss_db: 0.6084
2025/11/26 13:30:58 - mmengine - INFO - Epoch(train)    [1][ 210/6175]  lr: 7.0000e-03  eta: 36 days, 10:51:20  time: 0.3773  data_time: 0.0250  memory: 2377  loss: 4.4461  loss_prob: 2.8460  loss_thr: 1.0096  loss_db: 0.5904
2025/11/26 13:31:00 - mmengine - INFO - Epoch(train)    [1][ 215/6175]  lr: 7.0000e-03  eta: 36 days, 8:51:41  time: 0.3867  data_time: 0.0256  memory: 2377  loss: 4.4071  loss_prob: 2.8464  loss_thr: 0.9766  loss_db: 0.5841
2025/11/26 13:31:02 - mmengine - INFO - Epoch(train)    [1][ 220/6175]  lr: 7.0000e-03  eta: 36 days, 8:15:05  time: 0.3972  data_time: 0.0212  memory: 2377  loss: 4.3879  loss_prob: 2.8414  loss_thr: 0.9659  loss_db: 0.5805
2025/11/26 13:31:04 - mmengine - INFO - Epoch(train)    [1][ 225/6175]  lr: 7.0000e-03  eta: 36 days, 7:53:25  time: 0.4135  data_time: 0.0226  memory: 2377  loss: 4.4177  loss_prob: 2.8413  loss_thr: 0.9860  loss_db: 0.5905
2025/11/26 13:31:07 - mmengine - INFO - Epoch(train)    [1][ 230/6175]  lr: 7.0000e-03  eta: 36 days, 8:18:48  time: 0.4245  data_time: 0.0210  memory: 2377  loss: 4.3741  loss_prob: 2.8424  loss_thr: 0.9552  loss_db: 0.5766
2025/11/26 13:31:08 - mmengine - INFO - Epoch(train)    [1][ 235/6175]  lr: 7.0000e-03  eta: 36 days, 6:19:29  time: 0.4057  data_time: 0.0208  memory: 2377  loss: 4.3815  loss_prob: 2.8470  loss_thr: 0.9479  loss_db: 0.5867
2025/11/26 13:31:10 - mmengine - INFO - Epoch(train)    [1][ 240/6175]  lr: 7.0000e-03  eta: 36 days, 5:05:34  time: 0.3863  data_time: 0.0219  memory: 2377  loss: 4.5033  loss_prob: 2.8802  loss_thr: 1.0172  loss_db: 0.6059
2025/11/26 13:31:13 - mmengine - INFO - Epoch(train)    [1][ 245/6175]  lr: 7.0000e-03  eta: 36 days, 6:31:45  time: 0.4253  data_time: 0.0202  memory: 2377  loss: 4.5231  loss_prob: 2.8776  loss_thr: 1.0615  loss_db: 0.5840
2025/11/26 13:31:15 - mmengine - INFO - Epoch(train)    [1][ 250/6175]  lr: 7.0000e-03  eta: 36 days, 5:46:22  time: 0.4305  data_time: 0.0189  memory: 2377  loss: 4.4544  loss_prob: 2.8409  loss_thr: 1.0161  loss_db: 0.5974
2025/11/26 13:31:17 - mmengine - INFO - Epoch(train)    [1][ 255/6175]  lr: 7.0000e-03  eta: 36 days, 5:55:05  time: 0.4154  data_time: 0.0240  memory: 2377  loss: 4.4914  loss_prob: 2.8385  loss_thr: 1.0349  loss_db: 0.6180
2025/11/26 13:31:19 - mmengine - INFO - Epoch(train)    [1][ 260/6175]  lr: 7.0000e-03  eta: 36 days, 7:00:46  time: 0.4383  data_time: 0.0234  memory: 2377  loss: 4.4307  loss_prob: 2.8449  loss_thr: 1.0218  loss_db: 0.5640
2025/11/26 13:31:21 - mmengine - INFO - Epoch(train)    [1][ 265/6175]  lr: 7.0000e-03  eta: 36 days, 6:47:15  time: 0.4339  data_time: 0.0193  memory: 2377  loss: 4.3431  loss_prob: 2.8492  loss_thr: 0.9752  loss_db: 0.5187
2025/11/26 13:31:23 - mmengine - INFO - Epoch(train)    [1][ 270/6175]  lr: 7.0000e-03  eta: 36 days, 7:43:33  time: 0.4325  data_time: 0.0192  memory: 2377  loss: 4.3934  loss_prob: 2.8490  loss_thr: 0.9882  loss_db: 0.5562
2025/11/26 13:31:25 - mmengine - INFO - Epoch(train)    [1][ 275/6175]  lr: 7.0000e-03  eta: 36 days, 5:36:48  time: 0.4074  data_time: 0.0187  memory: 2377  loss: 4.4715  loss_prob: 2.8479  loss_thr: 1.0147  loss_db: 0.6089
2025/11/26 13:31:27 - mmengine - INFO - Epoch(train)    [1][ 280/6175]  lr: 7.0000e-03  eta: 36 days, 5:50:51  time: 0.3980  data_time: 0.0235  memory: 2377  loss: 4.4550  loss_prob: 2.8446  loss_thr: 1.0069  loss_db: 0.6035
2025/11/26 13:31:29 - mmengine - INFO - Epoch(train)    [1][ 285/6175]  lr: 7.0000e-03  eta: 36 days, 4:08:37  time: 0.4022  data_time: 0.0233  memory: 2377  loss: 4.4240  loss_prob: 2.8448  loss_thr: 0.9957  loss_db: 0.5835
2025/11/26 13:31:31 - mmengine - INFO - Epoch(train)    [1][ 290/6175]  lr: 7.0000e-03  eta: 36 days, 4:07:17  time: 0.3983  data_time: 0.0222  memory: 2377  loss: 4.3921  loss_prob: 2.8463  loss_thr: 0.9930  loss_db: 0.5527
2025/11/26 13:31:34 - mmengine - INFO - Epoch(train)    [1][ 295/6175]  lr: 7.0000e-03  eta: 36 days, 5:59:19  time: 0.4482  data_time: 0.0233  memory: 2377  loss: 4.3380  loss_prob: 2.8437  loss_thr: 0.9474  loss_db: 0.5468
2025/11/26 13:31:36 - mmengine - INFO - Epoch(train)    [1][ 300/6175]  lr: 7.0000e-03  eta: 36 days, 4:14:13  time: 0.4235  data_time: 0.0218  memory: 2377  loss: 4.3765  loss_prob: 2.8401  loss_thr: 0.9752  loss_db: 0.5612
2025/11/26 13:31:38 - mmengine - INFO - Epoch(train)    [1][ 305/6175]  lr: 7.0000e-03  eta: 36 days, 3:26:18  time: 0.3849  data_time: 0.0201  memory: 2377  loss: 4.4144  loss_prob: 2.8365  loss_thr: 0.9821  loss_db: 0.5958
2025/11/26 13:31:40 - mmengine - INFO - Epoch(train)    [1][ 310/6175]  lr: 7.0000e-03  eta: 36 days, 2:46:50  time: 0.3999  data_time: 0.0182  memory: 2377  loss: 4.3689  loss_prob: 2.8357  loss_thr: 0.9675  loss_db: 0.5657
2025/11/26 13:31:42 - mmengine - INFO - Epoch(train)    [1][ 315/6175]  lr: 7.0000e-03  eta: 36 days, 4:12:42  time: 0.4333  data_time: 0.0195  memory: 2377  loss: 4.3233  loss_prob: 2.8365  loss_thr: 0.9647  loss_db: 0.5222
2025/11/26 13:31:44 - mmengine - INFO - Epoch(train)    [1][ 320/6175]  lr: 7.0000e-03  eta: 36 days, 5:23:32  time: 0.4617  data_time: 0.0209  memory: 2377  loss: 4.3680  loss_prob: 2.8387  loss_thr: 0.9890  loss_db: 0.5404
2025/11/26 13:31:46 - mmengine - INFO - Epoch(train)    [1][ 325/6175]  lr: 7.0000e-03  eta: 36 days, 3:28:13  time: 0.4101  data_time: 0.0222  memory: 2377  loss: 4.3394  loss_prob: 2.8427  loss_thr: 0.9694  loss_db: 0.5272
2025/11/26 13:31:48 - mmengine - INFO - Epoch(train)    [1][ 330/6175]  lr: 7.0000e-03  eta: 36 days, 4:04:18  time: 0.4012  data_time: 0.0245  memory: 2377  loss: 4.2620  loss_prob: 2.8466  loss_thr: 0.9150  loss_db: 0.5003
2025/11/26 13:31:51 - mmengine - INFO - Epoch(train)    [1][ 335/6175]  lr: 7.0000e-03  eta: 36 days, 4:35:32  time: 0.4397  data_time: 0.0235  memory: 2377  loss: 4.2368  loss_prob: 2.8472  loss_thr: 0.9124  loss_db: 0.4771
2025/11/26 13:31:53 - mmengine - INFO - Epoch(train)    [1][ 340/6175]  lr: 7.0000e-03  eta: 36 days, 4:10:10  time: 0.4234  data_time: 0.0234  memory: 2377  loss: 4.2400  loss_prob: 2.8453  loss_thr: 0.9112  loss_db: 0.4835
2025/11/26 13:31:54 - mmengine - INFO - Epoch(train)    [1][ 345/6175]  lr: 7.0000e-03  eta: 36 days, 2:55:35  time: 0.3941  data_time: 0.0242  memory: 2377  loss: 4.2354  loss_prob: 2.8472  loss_thr: 0.8957  loss_db: 0.4925
2025/11/26 13:31:56 - mmengine - INFO - Epoch(train)    [1][ 350/6175]  lr: 7.0000e-03  eta: 36 days, 2:13:19  time: 0.3887  data_time: 0.0244  memory: 2377  loss: 4.2111  loss_prob: 2.8496  loss_thr: 0.8953  loss_db: 0.4662
